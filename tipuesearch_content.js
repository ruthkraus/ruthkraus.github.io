var tipuesearch = {"pages":[{"title":"About me","text":"Hello, my name is Ruth Kraus I like Python programming language and I use it for more than 5 years every day and like to use it for web development, for deployment technologies, for writing tests and many other cool things. This blog I've created to remember things which I already did or learning now or will learn, I think it will be mostly articles about usage python for web development. English is not my native language and feel free to correct me. Also my sorry if I write something wrong. ruthkraus@gmail.com","tags":"pages","url":"https://ruthkraus.github.io/about-me.html","loc":"https://ruthkraus.github.io/about-me.html"},{"title":"Soft touch to SQLAlchemy async I/O (asyncio) feature.","text":"From SQLAlchemy documentation since SQLAlchemy release 1.4 there present some support of async I/O: SQLAlchemy docs The new asyncio feature should be considered alpha level for the initial releases of SQLAlchemy 1.4. This is super new stuff that uses some previously unfamiliar programming techniques. The initial database API supported is the asyncpg asyncio driver for PostgreSQL. By the latest docs I can see now Asynchronous I/O (asyncio) The asyncio extension as of SQLAlchemy 1.4.3 can now be considered to be beta level software. API details are subject to change however at this point it is unlikely for there to be significant backwards-incompatible changes. For today the current release is 1.4.31 and I have an idea to run some tests to look closer on it. So first install virtual environment, install there SQLAlchemy, asyncpg driver and psycopg2-binary driver, I have an idea to do some tests with usual sync flow: $ python3.10 -m venv .venv $ source .venv/bin/activate $ ( .venv ) pip install sqlalchemy asyncpg psycopg2-binary $ pip freeze asyncpg == 0 .25.0 greenlet == 1 .1.2 psycopg2-binary == 2 .9.3 SQLAlchemy == 1 .4.31 Now we need postgresql database, run it with docker Docker , and set 2000 max_connections: docker run --rm \\ --name postgres \\ -p 5432 :5432 \\ -e POSTGRES_USER = postgres \\ -e POSTGRES_PASSWORD = postgres \\ -e POSTGRES_DB = postgres \\ postgres -N 2000 ... 2022 -02-11 08 :00:34.288 UTC [ 1 ] LOG: starting PostgreSQL 14 .1 ( Debian 14 .1-1.pgdg110+1 ) on x86_64-pc-linux-gnu, compiled by gcc ( Debian 10 .2.1-6 ) 10 .2.1 20210110 , 64 -bit We can check if -N 2000 was applied: docker run -it --rm --link postgres:postgres postgres psql -h postgres -U postgres ; Password for user postgres: psql ( 14 .1 ( Debian 14 .1-1.pgdg110+1 )) Type \"help\" for help. postgres = # show max_connections ; max_connections ----------------- 2000 ( 1 row ) So all is fine, our patient is prepared and waits for our commands. The case I think about to run ~35000 read/write operations against database, it should be ~ 50/50 %. ~50% read, 50% write operations. And its interesting to look at total time of execution and how many connections were utilized. Sync story I prepared some code that in my opinion does what I want in style I used to do usually: file sync_main.py import random import time from functools import partial from sqlalchemy import Column from sqlalchemy import DateTime from sqlalchemy import ForeignKey from sqlalchemy import func from sqlalchemy import Integer from sqlalchemy import String from sqlalchemy import create_engine from sqlalchemy.orm import Session from sqlalchemy.future import select from sqlalchemy.orm import declarative_base from sqlalchemy.orm import relationship from sqlalchemy.orm import selectinload from sqlalchemy.orm import sessionmaker Base = declarative_base () class A ( Base ): __tablename__ = \"a\" id = Column ( Integer , primary_key = True ) data = Column ( String ) create_date = Column ( DateTime , server_default = func . now ()) bs = relationship ( \"B\" ) class B ( Base ): __tablename__ = \"b\" id = Column ( Integer , primary_key = True ) a_id = Column ( ForeignKey ( \"a.id\" )) data = Column ( String ) def init_session (): engine = create_engine ( \"postgresql+psycopg2://postgres:postgres@localhost/postgres\" , echo = False , pool_size = 2000 , max_overflow = 0 , pool_timeout = 60 ) Base . metadata . drop_all ( bind = engine ) Base . metadata . create_all ( bind = engine ) session = sessionmaker ( engine , future = True ) return session def create_entities ( session , data ): with session () as session : with session . begin (): session . add_all ( [ A ( bs = [ B (), B ()], data = str ( data + 1 )), A ( bs = [ B ()], data = str ( data + 2 )), A ( bs = [ B (), B ()], data = str ( data + 3 )), ] ) def read_all_entities ( session , limit = 10 ): with session () as session : # for relationship loading, eager loading should be applied. stmt = select ( A ) . options ( selectinload ( A . bs )) . limit ( limit ) result = session . execute ( stmt ) for a1 in result . scalars (): for b1 in a1 . bs : print ( b1 ) def sync_main (): \"\"\"Main program function.\"\"\" session = init_session () create_entities_list = list () read_entities_list = list () for i in range ( 35000 ): if not random . choice ([ True , False ]): read_entities_list . append ( partial ( read_all_entities , session )) else : create_entities_list . append ( partial ( create_entities , session , random . randint ( 1 , 100_000 ))) tasks = [ * create_entities_list , * read_entities_list ] random . shuffle ( tasks ) print ( 'Tasks prepared for execution.' ) for i , t in enumerate ( tasks ): t () print ( 'created: ' , len ( create_entities_list )) print ( 'read: ' , len ( read_entities_list )) if __name__ == '__main__' : start = time . time () sync_main () print ( 'Total time: ' , time . time () - start ) Here we have 2 models with relationship, I prepared two lists of operations, then concat them in one big list and shuffle tasks, to have random order. Result: created: 17565 read: 17435 Total time: 203 .5927267074585 in that case total time is ~203 seconds and look at screenshot of DBeaver database dashboard: The DBeaver itself uses database connections, so in total we can see 3 connections on graph, I suppose two of them its DBeaver's connections. So I may be wrong, but here we utilize single connection from database for execute our flow syncronously. Async story one Check docs about questions how to use in whole SQLAlchemy asyncio extension, in addition there many articles were written about it, so its boring to repeat docs. import asyncio import itertools import random import time from sqlalchemy import Column from sqlalchemy import DateTime from sqlalchemy import ForeignKey from sqlalchemy import func from sqlalchemy import Integer from sqlalchemy import String from sqlalchemy.ext.asyncio import AsyncSession from sqlalchemy.ext.asyncio import create_async_engine from sqlalchemy.future import select from sqlalchemy.orm import declarative_base from sqlalchemy.orm import relationship from sqlalchemy.orm import selectinload from sqlalchemy.orm import sessionmaker Base = declarative_base () class A ( Base ): __tablename__ = \"a\" id = Column ( Integer , primary_key = True ) data = Column ( String ) create_date = Column ( DateTime , server_default = func . now ()) bs = relationship ( \"B\" ) # required in order to access columns with server defaults # or SQL expression defaults, subsequent to a flush, without # triggering an expired load __mapper_args__ = { \"eager_defaults\" : True } class B ( Base ): __tablename__ = \"b\" id = Column ( Integer , primary_key = True ) a_id = Column ( ForeignKey ( \"a.id\" )) data = Column ( String ) async def init_session (): engine = create_async_engine ( \"postgresql+asyncpg://postgres:postgres@localhost/postgres\" , future = True , echo = False , pool_size = 3000 , max_overflow = 20 , pool_timeout = 60 ) async with engine . begin () as conn : await conn . run_sync ( Base . metadata . drop_all ) async with engine . begin () as conn : await conn . run_sync ( Base . metadata . create_all ) # expire_on_commit=False will prevent attributes from being expired # after commit. async_session = sessionmaker ( engine , expire_on_commit = False , class_ = AsyncSession ) return async_session async def coro_create_entities ( async_session , data ): async with async_session () as session : async with session . begin (): session . add_all ( [ A ( bs = [ B (), B ()], data = str ( data + 1 )), A ( bs = [ B ()], data = str ( data + 2 )), A ( bs = [ B (), B ()], data = str ( data + 3 )), ] ) async def coro_read_all_entities ( async_session , limit = 10 ): async with async_session () as session : # for relationship loading, eager loading should be applied. stmt = select ( A ) . options ( selectinload ( A . bs )) . limit ( limit ) # for streaming ORM results, AsyncSession.stream() may be used. result = await session . stream ( stmt ) # result is a streaming AsyncResult object. async for a1 in result . scalars (): for b1 in a1 . bs : print ( b1 ) async def async_main (): \"\"\"Main program function.\"\"\" async_session = await init_session () create_entities = set () read_entities = set () for i in range ( 35000 ): if not random . choice ([ True , False ]): read_entities . add ( asyncio . create_task ( coro_read_all_entities ( async_session ))) else : create_entities . add ( asyncio . create_task ( coro_create_entities ( async_session , data = random . randint ( 1 , 100_000 )))) await asyncio . sleep ( 0 ) # trick to let switch context from creating tasks done , pending = await asyncio . wait ( itertools . chain ( create_entities , read_entities )) print ( \"Done: \" , len ( done )) print ( \"Pending: \" , len ( pending )) print ( 'created: ' , len ( create_entities )) print ( 'read: ' , len ( read_entities )) if __name__ == '__main__' : start = time . time () asyncio . run ( async_main ()) print ( 'Total time: ' , time . time () - start ) And result here is amazing !!! The total time is two times faster than in case with sync style: Done: 35000 Pending: 0 created: 17663 read: 17337 Total time: 116 .1717700958252 It utilizes ~100 database connections. The one thing you can see my trick that lets my script to switch attention to task execution from ‘for' loop that pushes tasks to event loop queue. Otherwise, if I don't do that, our 2000 pool will be exhausted by 2000 tasks in 3 seconds. Async story two (chunks) Here I decided to push tasks by chunks, to control optimal numbers of concurrent requests per unit of time. import asyncio import itertools import random import time from sqlalchemy import Column from sqlalchemy import DateTime from sqlalchemy import ForeignKey from sqlalchemy import func from sqlalchemy import Integer from sqlalchemy import String from sqlalchemy.ext.asyncio import AsyncSession from sqlalchemy.ext.asyncio import create_async_engine from sqlalchemy.future import select from sqlalchemy.orm import declarative_base from sqlalchemy.orm import relationship from sqlalchemy.orm import selectinload from sqlalchemy.orm import sessionmaker from itertools import zip_longest def chunker ( iterable , chunksize , filler ): return zip_longest ( * [ iter ( iterable )] * chunksize , fillvalue = filler ) Base = declarative_base () class A ( Base ): __tablename__ = \"a\" id = Column ( Integer , primary_key = True ) data = Column ( String ) create_date = Column ( DateTime , server_default = func . now ()) bs = relationship ( \"B\" ) # required in order to access columns with server defaults # or SQL expression defaults, subsequent to a flush, without # triggering an expired load __mapper_args__ = { \"eager_defaults\" : True } class B ( Base ): __tablename__ = \"b\" id = Column ( Integer , primary_key = True ) a_id = Column ( ForeignKey ( \"a.id\" )) data = Column ( String ) async def init_session (): engine = create_async_engine ( \"postgresql+asyncpg://postgres:postgres@localhost/postgres\" , future = True , echo = False , pool_size = 3000 , max_overflow = 20 , pool_timeout = 60 ) async with engine . begin () as conn : await conn . run_sync ( Base . metadata . drop_all ) async with engine . begin () as conn : await conn . run_sync ( Base . metadata . create_all ) # expire_on_commit=False will prevent attributes from being expired # after commit. async_session = sessionmaker ( engine , expire_on_commit = False , class_ = AsyncSession ) return async_session async def coro_create_entities ( async_session , data ): async with async_session () as session : async with session . begin (): session . add_all ( [ A ( bs = [ B (), B ()], data = str ( data + 1 )), A ( bs = [ B ()], data = str ( data + 2 )), A ( bs = [ B (), B ()], data = str ( data + 3 )), ] ) async def coro_read_all_entities ( async_session , limit = 10 ): async with async_session () as session : # for relationship loading, eager loading should be applied. stmt = select ( A ) . options ( selectinload ( A . bs )) . limit ( limit ) # AsyncSession.execute() is used for 2.0 style ORM execution # (same as the synchronous API). # for streaming ORM results, AsyncSession.stream() may be used. result = await session . stream ( stmt ) # result is a streaming AsyncResult object. async for a1 in result . scalars (): for b1 in a1 . bs : print ( b1 ) async def async_main (): \"\"\"Main program function.\"\"\" async_session = await init_session () create_entities_list = list () read_entities_list = list () for i in range ( 35000 ): if not random . choice ([ True , False ]): read_entities_list . append ( coro_read_all_entities ( async_session )) else : create_entities_list . append ( coro_create_entities ( async_session , data = random . randint ( 1 , 100_000 ))) tasks = [ * create_entities_list , * read_entities_list ] random . shuffle ( tasks ) for i , chunk in enumerate ( chunker ( tasks , 40 , None )): await asyncio . gather ( * ( t for t in chunk if t )) print ( 'created: ' , len ( create_entities_list )) print ( 'read: ' , len ( read_entities_list )) if __name__ == '__main__' : start = time . time () asyncio . run ( async_main ()) print ( 'Total time: ' , time . time () - start ) So as you can see from code I push by forthy requests (Tasks) per one chunk and we can see results: created: 17600 read: 17400 Total time: 102 .18556618690491 so here less total time of execution, I win 14 seconds !!! Its because I think its less load on database when I control chunks of tasks to run concurrently at one loop cycle. And of course DBeaver picture: The end So final words scenario time, sec sync 202.0 async 116.0 async chunked 102.2 And here you can look at all three runs on one graph. I hope it was interesting, feel free to comment below ;)","tags":"Blog","url":"https://ruthkraus.github.io/2022/02/sync-and-async-sqlalchemy.html","loc":"https://ruthkraus.github.io/2022/02/sync-and-async-sqlalchemy.html"},{"title":"Get results from Asyncio tasks those were interrupted by timeout","text":"So I ask myself how to do for example next thing with AsyncIO ? I have an ordered list of remote API 's urls and need to send data to the first of API 's that can respond < 1 sec, if API can't response in 1 sec - I need to initiate next sending to next API url in order to API 's url list. If API responds < 1 sec I need to notify user that data was sent successfully. If I have tasks that were initiated but were interrupted to send data ASAP to next API url, I want finally to know their results to make some valuable decision - for example to notify that data was also sent there. First I'll prepare simple flask app that can listen and answers for our requests with some data. import flask import time app = flask . Flask ( __name__ ) @app . route ( \"/url/<int:api_id>\" ) def handler ( api_id ): print ( f \"Sleep { api_id } seconds\" ) time . sleep ( api_id ) return flask . jsonify ({ \"result\" : f \"slept { sleep } seconds\" , \"api_id\" : api_id }) if __name__ == \"__main__\" : app . run ( debug = True , port = 8001 ) so flask app will listen on 8001 port and respond with timeout in order to api_id parameter. Write code that handles my expectations: import asyncio import logging import functools import requests import concurrent.futures logging . basicConfig ( level = logging . DEBUG ) logger = logging . getLogger ( __name__ ) def sync_loader ( url ): \"\"\" Sync blocking request \"\"\" logger . info ( f \"Sync download { url } \" ) return requests . get ( url ) . json () async def coro_loader ( url ): \"\"\" Runner for sync function in executor \"\"\" fn = functools . partial ( sync_loader , url ) loop = asyncio . get_event_loop () logger . info ( f \"start download async { url } \" ) return await loop . run_in_executor ( None , fn ) async def waiter ( pending_tasks ): \"\"\" Coroutine to wait pending tasks results and display results \"\"\" wait_for = 60 while not all ( map ( lambda x : x . done (), pending_tasks . values ())) and wait_for > 0 : logger . info ( \"Waiting for pending task results...\" ) await asyncio . sleep ( 1 ) wait_for -= 1 for api_id , task in pending_tasks . items (): if not task . done (): task . cancel () logger . warning ( f \"Postprocess { api_id } task was cancelled.\" ) continue logger . info ( f \"Postprocess pending task api_id: { api_id } ; { task . result () } \" ) async def download_async (): urls = { api_id : \"http://localhost:8001/url/ {0} \" . format ( api_id ) for api_id in [ 3 , 4 ]} urls [ 5 ] = \"http://localhost:8001/url/0\" # for example 5th url its a fast API pending_tasks = {} res = {} for api_id , url in urls . items (): task = asyncio . Task ( coro_loader ( url )) # create Task from coroutine try : # wrap asyncio.shield(task) to avoid of task cancellation # after 1 sec timeout res = await asyncio . wait_for ( asyncio . shield ( task ), timeout = 1 ) except concurrent . futures . TimeoutError : # add task that was interrupted to pending task mapping pending_tasks [ api_id ] = task logger . info ( f \"Add download task for { url } to pending tasks list.\" ) if not res : continue else : # show success message logger . info ( f \"Success with send data to { url } , in pending_tasks now\" f \" are { len ( pending_tasks ) } tasks.\" ) break loop = asyncio . get_event_loop () loop . create_task ( waiter ( pending_tasks )) loop = asyncio . get_event_loop () loop . create_task ( download_async ()) loop . run_forever () So code is much more clear now. I collect tasks those were interrupted to waiter() coroutine and there waiting for results. Example of log output: (.venv) ➜ as python worker.py INFO:__main__:start download async http://localhost:8001/url/3 INFO:__main__:Sync download http://localhost:8001/url/3 INFO:__main__:Add download task for http://localhost:8001/url/3 to pending tasks list. INFO:__main__:start download async http://localhost:8001/url/4 INFO:__main__:Sync download http://localhost:8001/url/4 INFO:__main__:Add download task for http://localhost:8001/url/4 to pending tasks list. INFO:__main__:start download async http://localhost:8001/url/0 INFO:__main__:Sync download http://localhost:8001/url/0 INFO:__main__:Success with send data to http://localhost:8001/url/0, in pending_tasks now are 2 tasks. INFO:__main__:Waiting for pending task results... INFO:__main__:Waiting for pending task results... INFO:__main__:Waiting for pending task results... INFO:__main__:Postprocess pending task api_id: 3; {'api_id': 3, 'result': 'slept 3 seconds'} INFO:__main__:Postprocess pending task api_id: 4; {'api_id': 4, 'result': 'slept 4 seconds'}","tags":"Blog","url":"https://ruthkraus.github.io/2018/06/handle-tasks-with-asyncio.html","loc":"https://ruthkraus.github.io/2018/06/handle-tasks-with-asyncio.html"},{"title":"Паттерн ДЕКОРАТОР","text":"Паттерн Декоратор динамически наделяет объект новыми возможностями и является гибкой альтернативой наследованию (субклассированию) в области расширения функциональности. Сomponent - абстрактный класс который наследуется ConcreteComponent. ConcreteComponent - объект поведение которого собираемся динамически расширять. Decorator реализует тот же интерфейс или абстрактный класс (в нашем случае абстрактный класс), что и декорируемый компонент). ConcreteDecoratorA - содержит переменную экземпляра в которой хранится декорируемый объект (Component) СoncreteDecoratorB - показано что декораторы могут расширять состояние компонента, если нужно. Декораторы могут добавлять новые методы, однако новое поведение обычно добавляется до или после вызова существующего метода компонента. Теперь попробуем использовать данный паттерн практически, допустим (навеяно примером книги) у нас есть некий набор напитков Чай, Кофе имеющих стоимость, и есть набор добавок к напиткам Молоко, Сахар которые тоже имеют стоимость. Готовый продукт подаваемый клиенту содержит напиток с добавками (или без) и в конечном итоге стоимость равна сумме стоимости всех ингридиентов. Допустим мы реализовали класс Напитка, который умеет возвращать его стоимость. Если мы реализуем класс добавку как класс - декоратор, мы сможем \"обертывать\" обьект напитка и добавлять стоимость добавки к стоимости напитка. Схематично это может выглядеть как то так, у нас есть объект Чай который декорирован объектом Добавка Сахар. Т.е. на этапе когда я создаю экземпляр класса добавки - Сахар, экземпляр класса напитка Чай у меня уже есть. Когда я создаю экземпляр декоратора-добавки Сахар я передаю ему уже готовый экземпляр напитка Чай. Цена готового напитка рассчитывается как цена Сахар + Чай, соответственно фактически экземпляр класса Сахар при вызове метода возвращающего цену должен вызвать метод возвращающий цену обернутого объекта (Чай) и потом добавить свою цену и вернуть общую стоимость. На самом деле вложенность может быть сколь угодно уровневой, допустим мы можем обернуть предыдущий пример еще в один тип добавки Молоко. Тогда общая цена напитка будет состоять из \"цена Чая\" + \"цена Сахара\" + \"цена Молока\". Т.е. при вызове метода расчета стоимости у экземпляра добавки Молоко ( который обертывает экземпляр Сахар, который в свою очередь содержит обернутый экземпляр Чай), вызовется метод расчета стоимости обернутого обьекта (Сахар), в свою очередь метод расчета стоимости экземпляра Сахар вызовет метод обернутого объекта Чай, добавит свою стоимость (Сахара) и вернет значение экземпляру Молоко. Экземпляр Молока добавит свои стоимость к возвращенному (Чай+Сахар) и вернет общую стоимость напитка. Немного запутанно, но на самом деле не очень сложно. Такие декорации можно комбинировать, очень гибко без изменения кода. Допустим можно сделать Чай с двойным Молоком, нужно лишь два раза обернуть экземпляр класса Чай декоратором Молоко. Диаграмма классов нашего примера будет выглядеть так: AbstractBeverage абстрактный класс напитка в котором мы определим методы cost() и getDescription(). cost() это абстрактный метод который должен быть реализован в классах реальных напитков. Метод getDescription() метод который наследуется классами настоящих напитков и можно будет использовать для получения названия напитка. GreenTea, BlackCoffee классы реализующие сущности конкретных напитков Кофе и Чай. Методы cost() в них возвращают конкретную стоимость. AbstractCondiments - абстрактный класс наследованный от AbstractBeverage, в нем мы переопределили getDescription() как абстратный, я хочу чтоб конкретные классы добавок обязаны были иметь свои собственные реализации getDescription(). Метод cost() также должен быть определен в конкретном классе добавки, это поведение определено в родительском классе AbstractBeverage. Sugar, Milk - конкретные классы реализующие AbstractCondiments. В конструктор классов я передаю экземпляр конкретного напитка и запоминаю его в переменной self.decorated . Таким образом в каждом экземпляре добавки я запоминаю обьект который в конечном итоге является производным от AbstractBeverage, так как мы все наследуем от него. self.decorated может содержать как конкретный экземпляр напитка, так и обернутую конструкцию добавка(напиток), при чем глубина вложений не важна, мы оперируем на уровне абстракции у которой в конечном итоге знаем, что можно вызвать cost() и getDescription(). Прелесть в том, что мы программируем не привязываясь к конкретным типам. Реализация у меня получилась похожая на нечто вот такое: from abc import ABCMeta , abstractmethod class AbstractBeverage ( metaclass = ABCMeta ): _description = \"Abstract beverage description\" @abstractmethod def cost ( self ): return NotImplementedError def getDescription ( self ): return self . _description class BlackCoffee ( AbstractBeverage ): _description = \"Black coffee\" def cost ( self ): return 0.50 class GreenTea ( AbstractBeverage ): _description = \"Green Tea\" def cost ( self ): return 0.15 class AbstractCondiments ( AbstractBeverage , metaclass = ABCMeta ): @abstractmethod def getDescription ( self ): return NotImplementedError class Sugar ( AbstractCondiments ): _description = \"Sugar\" def __init__ ( self , decorated ): self . decorated = decorated def cost ( self ): return self . decorated . cost () + 0.30 def getDescription ( self ): return self . decorated . getDescription () + \" and \" + self . _description class Milk ( AbstractCondiments ): _description = \"Milk\" def __init__ ( self , decorated ): self . decorated = decorated def cost ( self ): return self . decorated . cost () + 0.25 def getDescription ( self ): print ( \"Bon appetit !!!\" ) return self . decorated . getDescription () + \" and \" + self . _description Теперь попробуем \"приготовить\" Чай без добавок: tea = GreenTea() tea.cost() Out[24]: 0.15 tea.getDescription() Out[25]: 'Green Tea' А теперь приготовим кофе с молоком и сахаром: - создадим экземпляр BlackCoffee coffee = BlackCoffee() добавим сахара - создавая экземпляр Sugar - передадим созданный экземпляр BlackCofee и таким образом экземпляр Sugar запомнит экземпляр BlackCofee в переменной self.decorated . Мы таким образом декорируем (обертываем) экземпляр BlackCofee : coffee = Sugar(coffee) добавим аналогично молоко, теперь coffee это уже не просто чистый кофе а экземпляр Sugar содержащий в себе ссылку на чистый кофе экземпляр BlackCoffee , созданный на первом шаге. coffee = Milk(coffee) теперь переменная coffee содержит ссылку на конструкцию из чего то, что схематично можно представить как Milk(Sugar(BlackCoffee)) Можно получить стоимость полученного напитка: coffee.cost() Out[31]: 1.05 и правильно в общем получается если сложить цены ингридиентов: цена кофе = 0,50 цена сахара = 0,30 цена молока = 0,25 0,50 + 0,30 + 0,25 = 1,05 теперь можно обернуть еще раз Milk и увидим что стоимость увеличится: coffee = Milk(coffee) coffee.cost() Out[34]: 1.3 Таким образом можно вкладывать экземпляры и метод cost() будет вызываться по цепочке, в конечном итоге мы получим общую стоимость. def cost ( self ) : return self . decorated . cost () + 0 . 25 Это происходит потому что мы вызываем метод cost() у чего то обернутого self.decorated и в свою очередь если у \"чего то обернутого\" в свою очередь содержится обернутый объект у этого объекта также вызовется метод cost(). Так будет происходить пока не дойдет очередь до обьекта у которого нет \"чего то обернутого\" и у него вызовется метод cost(), он вернет значение вызвавшему его экземпляру, тот добавит свою стоимость и вернет выше, т.е цепочка пойдет в обратном направлении. ( Milk cost ()) -> Sugar ( cost ()) -> BlackCoffee ( cost ()) ( Milk ( return 0.80+0.25 ) <- Sugar ( return 0.50+0.30 ) <- BlackCoffee ( return 0.50 )) Вывод Наследование одна из форм расширения, но оно не всегда обеспечивает гибкость архитектуры. Следует предесмотреть возможность расширения без изменения существующего кода. Композиция и делегирование часто используются для динамического добавления нового поведения (в нашем случае мы делегируем вызов cost() обьекту decorated). Типы декораторов соответствуют типам декорируемых компонентов (соответстве может быть достигнуто посредством наследования или реализации интерфейса) Компонент может декорироваться любым количеством декораторов. Декораторы изменяют поведение декорируемых компонентов, добавляя новую функциональность до или после или даже вместо вызовов методов компонентов.","tags":"Blog","url":"https://ruthkraus.github.io/2017/08/pattern-decorator.html","loc":"https://ruthkraus.github.io/2017/08/pattern-decorator.html"},{"title":"Паттерн НАБЛЮДАТЕЛЬ","text":"Паттерн НАБЛЮДАТЕЛЬ определяет отношение \"один ко многим\" между объектами таким образом, что при изменении состояния одного объекта происходит автоматическое оповещение и обновление всех зависимых объектов. Схема данного определения может выглядеть примерно так. Есть субъект (Subject) и объекты-наблюдатели (Object) которые определяют отношение \"один ко многим\". Наблюдатели зависят от субъекта - при изменении состояния последнего наблюдатели получают оповещения. Данный паттерн еще называют Publisher-Subscriber (издатель-подписчик), поскольку отношения издателя и подписчиков характеризуют действие данного паттерна: подписчики подписываются email-рассылку определенного сайта. Сайт-издатель с помощью email-рассылки уведомляет всех подписчиков о изменениях. А подписчики получают изменения и производят определенные действия: могут зайти на сайт, могут проигнорировать уведомления и т.д. Паттерн наблюдатель строится на основе классов, реализующих интерфейсы субъекта и наблюдателя. Диаграмма классов выглядит вот так: Итак, каждый субъект может иметь много наблюдателей. Каждый потенциальный наблюдатель должен реализовать интерфейс Observer который содержит единственный метод update() который вызывается при изменении состояния субъекта. Класс ConcreteObserver реализация интерфейса Observer, каждый наблюдаетль регистрируется у конкретного субьекта для получения обновлений. Субьект реализует интерфейс Subject. Кроме методов регистрации, удаления, субъект также реализует метод notifyObservers() оповещающий всех текущих наблюдателей об изменении состояния. Субъект также может иметь методы set- и get- для изменения состояния. На базе слабосвязанных архитектур строятся гибкие ОО-системы, которые хорошо адаптируются к изменениям благодаря минимальным зависимостям между оъектами. Опишем данные интерфейсы наблюдателя и субъекта. В реализации конкретного класса субъекта представим что у нас есть класс абстракция некоего шлагбаума, который перекрывает движение и он будет рассылать всем наблюдателям свое состояние открыто-закрыто. from abc import ABCMeta , abstractmethod class ISubject ( metaclass = ABCMeta ): @abstractmethod def registerObserver ( self , observer ): raise NotImplementedError () @abstractmethod def removeObserver ( self , observer ): raise NotImplementedError () @abstractmethod def notifyObservers ( self ): raise NotImplementedError () class IObserver ( metaclass = ABCMeta ): @abstractmethod def update ( self , subject , arg ): raise NotImplementedError () class ConcreteSubject : def __init__ ( self ): self . _observers = [] self . changed = 0 self . state = \"open\" def registerObserver ( self , observer ): if observer not in self . _observers : print ( \"Register observer: {0} \" . format ( observer . name )) self . _observers . append ( observer ) def removeObserver ( self , observer ): print ( \"Remove observer: {0} \" . format ( observer . name )) self . _observers . remove ( observer ) def notifyObservers ( self , arg = None ): ''' If 'changed' indicates that this object has changed, notify all its observers, then call clearChanged(). Each observer has its update() called with two arguments: this observable object and the generic 'arg'. ''' if not self . changed : return observers = self . _observers [:] for observer in observers : observer . update ( self , arg ) self . clearChanged () def deleteObservers ( self ): self . _observers = [] def countObservers ( self ): return len ( self . _observers ) def setChanged ( self ): self . changed = 1 def clearChanged ( self ): self . changed = 0 def hasChanged ( self ): return self . changed def setState ( self , state ): self . state = state self . changed = 1 self . notifyObservers ( arg = self . state ) class ConcreteObserver : def __init__ ( self , name ): self . name = name def update ( self , observable , arg ): print ( \"Observer {2} Got update from Subject: {0} with arg: {1} \" . format ( observable , arg , self . name )) print ( \"State (arg) = {0} \" . format ( arg )) print ( \"State (Subject) = {0} \" . format ( observable . state )) observer1 = ConcreteObserver ( \"Observer-1\" ) observer2 = ConcreteObserver ( \"Observer-2\" ) observer3 = ConcreteObserver ( \"Observer-3\" ) subject1 = ConcreteSubject () subject1 . registerObserver ( observer1 ) subject1 . registerObserver ( observer2 ) subject1 . registerObserver ( observer3 ) subject1 . setState ( \"closed\" ) subject1 . removeObserver ( observer3 ) subject1 . setState ( \"opened\" ) ISubject: представляет наблюдаемый объект (Субъект). Определяет три основных метода, необходимых для реализации субъекта: - registerObserver() (для добавления наблюдателя), - removeObserver() (удаление набюдателя) - notifyObservers() (уведомление наблюдателей) ConcreteSubject: конкретная реализация интерфейса ISubject. В этом классе приведена чуть большая реализация чем указано на диаграмме классов, добавлены несколько методов. - Для управления списком наблюдаетелей self._observers : - deleteObservers() - позволяет очистить список подписчиков-наблюдаетелей - countObservers() - возвращает текущее число подписчиков данного обьекта Для управления состянием self.changed setChanged() clearChanged() hasChanged() Для тестирования мне нужен метод с помощью которого я смогу менять состояние Subject объекта self.state (открыт или закрыт шлагбаум), которое отсылается всем наблюдателям: setState() IObserver: представляет интерфейс наблюдателя, который подписывается на все уведомления наблюдаемого объекта. Определяет метод update(), который вызывается наблюдаемым объектом для уведомления наблюдателя. ConcreteObserver: конкретная реализация интерфейса IObserver. Также дополнен для удобства параметром name чтобы как то различать подписчиков-наблюдателей. В тестовом коде происходит следующее: - создание наблюдателей: observer1 = ConcreteObserver ( \"Observer-1\" ) observer2 = ConcreteObserver ( \"Observer-2\" ) observer3 = ConcreteObserver ( \"Observer-3\" ) создание субъекта (обьекта за которым ведется наблюдение): subject1 = ConcreteSubject () происходит подписка-регистрация на получение обновлений состяния субъекта: subject1 . registerObserver ( observer1 ) subject1 . registerObserver ( observer2 ) subject1 . registerObserver ( observer3 ) происходит рассылка нового состяния: subject1 . setState ( \"closed\" ) удаление наблюдателя из списка рассылки: subject1 . removeObserver ( observer3 ) происходит повторная рассылка нового состояния, видно что observer3 не получил ничего так как был удален из списка оповещаемых наблюдателей: subject1 . setState ( \"opened\" ) Вывод выглядит как то так: Register observer: Observer-1 Register observer: Observer-2 Register observer: Observer-3 Observer Observer-1 Got update from Subject: <__main__.ConcreteSubject object at 0x7f2799608710> with arg: closed State (arg) = closed State (Subject) = closed Observer Observer-2 Got update from Subject: <__main__.ConcreteSubject object at 0x7f2799608710> with arg: closed State (arg) = closed State (Subject) = closed Observer Observer-3 Got update from Subject: <__main__.ConcreteSubject object at 0x7f2799608710> with arg: closed State (arg) = closed State (Subject) = closed Remove observer: Observer-3 Observer Observer-1 Got update from Subject: <__main__.ConcreteSubject object at 0x7f2799608710> with arg: opened State (arg) = opened State (Subject) = opened Observer Observer-2 Got update from Subject: <__main__.ConcreteSubject object at 0x7f2799608710> with arg: opened State (arg) = opened State (Subject) = opened На данный момент мы используем один из вариантов информирования наблюдателя о состоянии - это push-модель, при которой наблюдаемый объект передает (иначе говоря толкает - push) принудительно данные о своем состоянии, то есть передает в виде параметра метода update() наблюдателю. Альтернативой push-модели является pull-модель, когда наблюдатель вытягивает (pull) из наблюдаемого объекта данные о состоянии с помощью дополнительных методов. Переработаем немного код, превратим нашу модель в pull - модель. изменим код метода setState, уберем передачу состяния через параметр напрямую: def setState ( self , state ): self . state = state self . changed = 1 self . notifyObservers () добавим метод получения состяния субьекта, чтобы наблюдатель мог сам получить состояние у субъекта: def getState ( self , state ): return self . state A вот код наблюдателя тоже поменяется, нам нужно чтобы наблюдатель вызывал метод getState() чтобы узнать состояние (таким образом мы можем инкапсулировать значение состояния переменной state , сделаем ее приватной принадлежащей внутренней реализации Subject, что означает что клиенты наблюдатели не должны обращаться ко внутреннему состоянию субъекта, а должны пользоваться методом getState() ): class ConcreteObserver : def __init__ ( self , name ): self . name = name def update ( self , observable , arg ): print ( \"Observer {2} Got update from Subject: {0} with arg: {1} \" . format ( observable . getState (), arg , self . name )) print ( \"State (arg) = {0} \" . format ( arg )) print ( \"State (Subject) = {0} \" . format ( observable . getState ())) Полностью код и результат будут выглядеть вот так: from abc import ABCMeta , abstractmethod class ISubject ( metaclass = ABCMeta ): @abstractmethod def registerObserver ( self , observer ): raise NotImplementedError () @abstractmethod def removeObserver ( self , observer ): raise NotImplementedError () @abstractmethod def notifyObservers ( self ): raise NotImplementedError () class IObserver ( metaclass = ABCMeta ): @abstractmethod def update ( self , subject , arg ): raise NotImplementedError () class ConcreteSubject : def __init__ ( self ): self . _observers = [] self . changed = 0 self . _state = \"open\" def registerObserver ( self , observer ): if observer not in self . _observers : print ( \"Register observer: {0} \" . format ( observer . name )) self . _observers . append ( observer ) def removeObserver ( self , observer ): print ( \"Remove observer: {0} \" . format ( observer . name )) self . _observers . remove ( observer ) def notifyObservers ( self , arg = None ): ''' If 'changed' indicates that this object has changed, notify all its observers, then call clearChanged(). Each observer has its update() called with two arguments: this observable object and the generic 'arg'. ''' if not self . changed : return observers = self . _observers [:] for observer in observers : observer . update ( self , arg ) self . clearChanged () def deleteObservers ( self ): self . _observers = [] def setChanged ( self ): self . changed = 1 def clearChanged ( self ): self . changed = 0 def hasChanged ( self ): return self . changed def countObservers ( self ): return len ( self . _observers ) def setState ( self , state ): self . _state = state self . changed = 1 self . notifyObservers () def getState ( self ): return self . _state class ConcreteObserver : def __init__ ( self , name ): self . name = name def update ( self , observable , arg ): print ( \"Observer {2} Got update from Subject: {0} with arg: {1} \" . format ( observable . getState (), arg , self . name )) print ( \"State (arg) = {0} \" . format ( arg )) print ( \"State (Subject) = {0} \" . format ( observable . getState ())) observer1 = ConcreteObserver ( \"Observer-1\" ) observer2 = ConcreteObserver ( \"Observer-2\" ) observer3 = ConcreteObserver ( \"Observer-3\" ) subject1 = ConcreteSubject () subject1 . registerObserver ( observer1 ) subject1 . registerObserver ( observer2 ) subject1 . registerObserver ( observer3 ) subject1 . setState ( \"closed\" ) subject1 . removeObserver ( observer3 ) subject1 . setState ( \"opened\" ) Register observer: Observer-1 Register observer: Observer-2 Register observer: Observer-3 Observer Observer-1 Got update from Subject: closed with arg: None State (arg) = None State (Subject) = closed Observer Observer-2 Got update from Subject: closed with arg: None State (arg) = None State (Subject) = closed Observer Observer-3 Got update from Subject: closed with arg: None State (arg) = None State (Subject) = closed Remove observer: Observer-3 Observer Observer-1 Got update from Subject: opened with arg: None State (arg) = None State (Subject) = opened Observer Observer-2 Got update from Subject: opened with arg: None State (arg) = None State (Subject) = opened Как видно теперь Субъект рассылает оповещения о изменении состояния, но не рассылает это состояние, а наблюдатели вызывают соответствующий метод Субъекта чтобы получить состояние. Таким образом если состояние Субъекта это большой обьект с кучей информации, можно реализовать методы которые отдают части этой информации и таким образом наблюдатели смогут решать какую часть информации им интересно получить. В книге приведен пример когда Субьект хранит 3 параметра, но не всем клиентам нужны сразу все 3 параметра, кому то нужен 1 кому то 2. Поэтому реализация каждого наблюдателя включает получение только тех данных которые нужны. Вывод Паттерн НАБЛЮДАТЕЛЬ это реализация отношений один ко многим. Новый принцип проектирования - стремиться к слабой связанности между объектами.","tags":"Blog","url":"https://ruthkraus.github.io/2017/07/pattern-observer.html","loc":"https://ruthkraus.github.io/2017/07/pattern-observer.html"},{"title":"Паттерн СТРАТЕГИЯ","text":"Многим разработчикам в процессе работы приходится решать похожие (если практически не идентичные) задачи и приходить к похожим решениям. Поэтому и появились \"паттерны\", как шаблоны наилучших решений каких-то задач, позволяющие получить максимально гибкие решения, дающие возможность повторного использования кода. \" Паттерны\", в моем случае до сих пор оставались чем то немного пугающим словом, но желание познакомиться с ними взяло верх над страхом не разобраться с чем то и я решил, что попытаюсь. По каждой пройденной теме я буду делать маленькие заметки с реализацией того или иного паттерна на моем любимом языке Python. Имея некоторый опыт и скорее всего несознательно приходя к решениям которые уже где то описаны как готовые, я начал знакомиться с паттернами проектирования по книге Эрика Фримен и Элизабет Фримен \"Паттерны проектирования\". Саму книгу можно купить тут Итак, некоторые принципы проектирования упомянутые авторами в первой главе: Выделить аспекты приложения которые изменяются и отделить их от тех которые не изменяются. \"Отделять изменяемое от постоянного\" Программировать на уровне интерфейсов, а не реализации. Отдавать предпочтение композиции, а не наследованию. Тут следует заметить, что в понятия инкапуляции, полиморфизма, наследования и композиции мне уже достаточно ясны на этот момент. Инкапсуляция своими словами это отделение от главного содержания чего то второстепенного в отдельное место, \"капсулу\". Часто относительно программирования инкапсуляция означает выявление и отделение каких то сущностей из цельного блока программы с целью улучшить структуру и иногда скрыть внутреннюю реализацию сущности (часто чтобы скрыть и предотвратить изменение частных \"приватных\" данных напрямую извне). Паттерн СТРАТЕГИЯ Паттерн **Стратегия** определяет семейство алгоритмов, инкапсулирует каждый из них и обеспечивает их взаимозаменяемость. Он позволяет модифицировать алгоритмы независимо от их использования на стороне клиента. К слову сказать под алгоритмом как я понимаю можно рассматривать любое поведение сущности. Т.к. поведение и есть некий алгоритм. В качестве примера авторы приводят модель утиного пруда, было показано как простое наследование не позволяет создать легко изменяемую модель. И в конечном итоге получилась вот такое решение: Поведение уточек вынесено (инкапсулировано) и представлено двумя различными интерфейсами FlyBehavior и QuackBehavior. Сущности FlyWithWings, FlyNoWay реализуют уже настоящие поведения - \"уточка летит с помощью крыльев\", \"уточка не летает\". Сущности Quack, Squeak, MuteQuack реализуют интерфейс QuackBehavior и соответственно реализуют уже какие то реальные качества, \"крякает\", \"пищит\", \"не издает звуков\". Эти сущности и рассматриваются как алгоритмы, ведь действительно они определяют некие разные поведения. В абстрактный класс Duck \"вмонтированы\" (композиция) два объекта, представленные переменными типа интерфейса FlyBehavior и QuackBehavior, flyBehavior и quackBehavior соответственно. Получается клиент (Duck) использует инкапсулированные алгоритмы (сущности). Вдобавок Duck содержит набор методов позволяющих оперировать (менять) поведения, вызывать конкретные методы поведений. Из абстрактного класса Duck могут быть уже наследованы реальные \"утки\" MallardDuck, RubberDuck в которых может быть переопределен допустим метод отображения (как утка выглядит) и из которых уже можно создавать реальные экземпляры уток. Сам смысл примера в том что нужно выделить поведение (алгоритм), вынести в отдельную сущность и потом встроить (композировать) эту инкапсулированную сущность в код откуда она была вынесена. Ну и как видим соблюдено условие программировать на уровне интерфейсов - видим что в Duck были встроены именно интерфейсы а не какие то реальные классы. Это вносит гибкость, мы допустим можем легко добавить некий новый алгоритм поведения и использовать его не меняя кода реализации конкретной утки, можно просто установить новое поведение. Вот еще пример, допустим у нас есть персонажи, у которых есть возможность носить оружие. У оружия есть какие то персональные качества, название, сила удара. Пусть персонажи могут принимать и пользоваться любым оружием. Для примера пусть будет два персонажа Рыцарь (Knight) и Вор (Thief). Отделим (инкапсулируем) поведение оружия и применив композицию встроим оружие в обьект который будет представлять персонаж. Диаграмма классов будет выглядеть так: Чтобы реализовать интерфейс на Python я использую абстрактный класс с абстрактным методом, таким образом клиент не сможет создать экземпляр и будет вынужден переопределить абстрактный метод. Второй способ который я нашел - это способ основанный полностью на соглашении, т.е. объявляется обычный класс, методы которого возвращают NotImplemented. Таким образом клиентский код должен наследоваться и переопределять эти методы. К сожалению в Python нет специальной конструкции вроде interface как в Java, но способы реализовать абстракции к счастью имеются. Итак интерфейс и классы Knife, Sword реализующие оружие - выглядят так: from abc import ABCMeta , abstractmethod class IWeaponBehaviour ( metaclass = ABCMeta ): @abstractmethod def use_weapon ( self ): raise NotImplementedError () # 2nd approach #class IWeaponBehaviour: # def use_weapon(self): # raise NotImplementedError() class KnifeBehaviour ( IWeaponBehaviour ): def use_weapon ( self ): print ( \"Knife hit...\" ) print ( \"Damage 2 ...\" ) class SwordBehaviour ( IWeaponBehaviour ): def use_weapon ( self ): print ( \"Sword hit...\" ) print ( \"Damage 5 ...\" ) Классы реализуют метод интерфейса use_weapon() , уникальный для каждого типа оружия. Абстрактный класс персонажа и конкретные классы персонажей выглядят так: class AbstractCharacter ( metaclass = ABCMeta ): @property @abstractmethod def weapon ( self ): # IWeaponBehaviour object raise NotImplementedError () def set_weapon ( self , wb ): self . weapon = wb @abstractmethod def fight ( self ): raise NotImplementedError () def use_weapon ( self ): self . weapon . use_weapon () class Thief ( AbstractCharacter ): weapon = KnifeBehaviour () def fight ( self ): print ( \"Thief do 1 step\" ) self . use_weapon () class Knight ( AbstractCharacter ): weapon = SwordBehaviour () def fight ( self ): print ( \"Knife do 2 steps\" ) self . use_weapon () Класс конкретного персонажа использует конкретное поведение оружия, у абстрактного класса AbstractCharacter есть метод set_weapon() позволяющий менять оружие персонажа \"на лету\" и метод use_weapon() позволяющий использовать оружие. Поведение оружия используется как свойство, тут используется композиция, мы используем инкапсулированый объект Оружие в объекте Персонаж. Полный код выглядит вот так: # -*- coding: utf-8 -*- \"\"\" Created on Thu Jul 27 09:36:35 2017 @author: biceps \"\"\" from abc import ABCMeta , abstractmethod class IWeaponBehaviour ( metaclass = ABCMeta ): @abstractmethod def use_weapon ( self ): raise NotImplementedError () # 2nd approach #class IWeaponBehaviour: # def use_weapon(self): # raise NotImplementedError() class KnifeBehaviour ( IWeaponBehaviour ): def use_weapon ( self ): print ( \"Knife hit...\" ) print ( \"Damage 2 ...\" ) class SwordBehaviour ( IWeaponBehaviour ): def use_weapon ( self ): print ( \"Sword hit...\" ) print ( \"Damage 5 ...\" ) class AbstractCharacter ( metaclass = ABCMeta ): @property @abstractmethod def weapon ( self ): # IWeaponBehaviour object raise NotImplementedError () def set_weapon ( self , wb ): self . weapon = wb @abstractmethod def fight ( self ): raise NotImplementedError () def use_weapon ( self ): self . weapon . use_weapon () class Thief ( AbstractCharacter ): weapon = KnifeBehaviour () def fight ( self ): print ( \"Thief do 1 step\" ) self . use_weapon () class Knight ( AbstractCharacter ): weapon = SwordBehaviour () def fight ( self ): print ( \"Knife do 2 steps\" ) self . use_weapon () thief = Thief () thief . fight () thief . set_weapon ( SwordBehaviour ()) thief . fight () knight = Knight () knight . fight () в конце приведен небольшой проверочный код: thief = Thief () # cоздадим персонаж Thief thief . fight () # ударим оружием Thief - Knife по умолчанию thief . set_weapon ( SwordBehaviour ()) # дадим Thief другое оружие - Sword thief . fight () # попросим Вора ударить Мечом knight = Knight () # создадим Рыцаря knight . fight () # попросим Рыцаря ударить Мечом Результаты выглядят так: Thief do 1 step Knife hit ... Damage 2 ... Thief do 1 step Sword hit ... Damage 5 ... Knife do 2 steps Sword hit ... Damage 5 ... Выводы Итак общий принцип используемый в паттерне СТРАТЕГИЯ это отделение неких сущностей в отдельные классы, которые можно использовать в клиентском коде с помощью композиции. Таким образом появляется возможность модифицировать эти сущности отдельно от кода клиента. В этом заключается гибкость и простота добавления новых сущностей и простота использования на стороне клиента.","tags":"Blog","url":"https://ruthkraus.github.io/2017/07/pattern-strategy.html","loc":"https://ruthkraus.github.io/2017/07/pattern-strategy.html"},{"title":"Postgresql DB dump / restore","text":"For some purposes, for example to have backup copies of database we need to create dump of database. Dump database To dump database we can use command line utility pg_dump . To make dump of database haircolors from previous examples, the usage might looks like: sudo -u postgres pg_dump -v -d haircolors > haircolors.dump Dump can be downloaded from here After that we will have haircolors.dump file, that contains plain SQL text: -- -- PostgreSQL database dump -- -- Dumped from database version 9.5.7 -- Dumped by pg_dump version 9.5.7 -- Started on 2017-07-06 10:38:13 MSK SET statement_timeout = 0 ; SET lock_timeout = 0 ; SET client_encoding = 'UTF8' ; SET standard_conforming_strings = on ; SET check_function_bodies = false ; SET client_min_messages = warning ; SET row_security = off ; -- -- TOC entry 1 (class 3079 OID 12395) -- Name: plpgsql; Type: EXTENSION; Schema: -; Owner: -- CREATE EXTENSION IF NOT EXISTS plpgsql WITH SCHEMA pg_catalog ; -- -- TOC entry 2240 (class 0 OID 0) -- Dependencies: 1 -- Name: EXTENSION plpgsql; Type: COMMENT; Schema: -; Owner: -- COMMENT ON EXTENSION plpgsql IS 'PL/pgSQL procedural language' ; SET search_path = public , pg_catalog ; SET default_tablespace = '' ; SET default_with_oids = false ; -- -- TOC entry 184 (class 1259 OID 16728) -- Name: address; Type: TABLE; Schema: public; Owner: postgres -- CREATE TABLE address ( id integer NOT NULL , building integer NOT NULL , flat_no integer NOT NULL , street character varying ( 128 ) NOT NULL , city_id integer ); The command pg_dump has parameter -F, —format=c|d|t|p that sets output file format (custom, directory, tar, plain text (default)) Restore database Restore it's easy: psql dbname < infile or we can use utility pg_restore if we previously used pg_dump with -F parameter that was not default (not plain text). pg_dump -Fc dbname > filename pg_restore -d dbname filename More info SQL Dump","tags":"Blog","url":"https://ruthkraus.github.io/2017/07/db-postgresql-dump-restore.html","loc":"https://ruthkraus.github.io/2017/07/db-postgresql-dump-restore.html"},{"title":"Выборка данных из нескольких таблиц ( JOIN )","text":"Задача: получить полный адрес покупателя. Вспомним, что информация о покупателяx после нормализации находится теперь в 5 -ти разных таблицах. Содержимое таблиц выглядит так: haircolors = # select * from person ; person_id | firstname | lastname | phonenumber | address_id -----------+-----------+----------+--------------+------------ 1 | Денис | Петров | + 79784567897 | 1 2 | Юлия | Бабкина | + 79784168585 | 2 ( 2 rows ) haircolors = # select * from address ; id | building | flat_no | street | city_id ----+----------+---------+-------------------------+--------- 1 | 77 | 54 | ул . Александра Косарева | 1 2 | 1 | 55 | ул . Кесаева | 1 ( 2 rows ) haircolors=# select * from city; city_id | city_name ---------+------------- 1 | Севастополь (1 row) haircolors=# select * from zip_code_catalog ; street | zip_code -------------------------+---------- ул. Александра Косарева | 299006 ул. Кесаева | 299003 (2 rows) haircolors=# select * from zip_code; zip_code ---------- 299006 299003 (2 rows) Для того чтоб получить информацию воспользуемся INNER JOIN : SELECT person_id , firstname , lastname , phonenumber , a . street , building , a . flat_no , zip_code , city_name FROM person AS p INNER JOIN address AS a ON p . address_id = a . id INNER JOIN city AS c ON a . city_id = c . city_id INNER JOIN zip_code_catalog AS z ON a . street = z . street ; В результате получим таблицу с необходимой информацией о покупателях: haircolors = # SELECT person_id, firstname, lastname, phonenumber, a.street, building, a.flat_no, zip_code, city_name FROM person AS p INNER JOIN address AS a ON p.address_id = a.id INNER JOIN city AS c ON a.city_id = c.city_id INNER JOIN zip_code_catalog AS z ON a.street = z.street; person_id | firstname | lastname | phonenumber | street | building | flat_no | zip_code | city_name -----------+-----------+----------+--------------+-------------------------+----------+---------+----------+------------- 1 | Денис | Петров | + 79784567897 | ул . Александра Косарева | 77 | 54 | 299006 | Севастополь 2 | Юлия | Бабкина | + 79784168585 | ул . Кесаева | 1 | 55 | 299003 | Севастополь ( 2 rows ) Вывод Наглядно видно, что запросы для получения выборок данных которые находятся в разных таблицах иногда могут быть скажем так не такими уж краткими. В некоторых случаях я думаю уместно будет произвести денормализацию, т.е. выполнить процесс, обратный нормализации, теряя несколько в независимости данных, но приобретая удобство и, возможно, в некоторых случаях улучшая производительность. Ресурсы http://www.postgresqltutorial.com https://www.tutorialspoint.com/postgresql","tags":"Blog","url":"https://ruthkraus.github.io/2017/07/db-postgresql-joins.html","loc":"https://ruthkraus.github.io/2017/07/db-postgresql-joins.html"},{"title":"Процедура нормализации данных и нормальные формы данных (4НФ, 5НФ).","text":"Завершаю серию заметок о нормализации, сведениями о понятиях более высоких нормальных форм 4НФ и 5НФ (чтобы иметь небольшую справку). Большей частью это цитирование труда Криса Дж. Дейта, с его же примерами. Поэтому возможны упоминания глав, и ссылок на литературу, присутствующую в книге. Четвертая нормальная форма 4НФ. Эта форма для многозначных зависимостей, когда значения - таблицы. Переменная отношения R находится в четвертой нормальной форме тогда и только тогда, когда в случае существования таких подмножеств A и В атрибутов этой переменной отношения R, для которых выполняется неривиальная многозначная зависимость A -> -> B, все атрибуты отношения R также зависят от атрибута А. Когда приходится иметь дело с переменной отношения которая содержит как атрибуты - отношения, { COURSE , TEXTS , TEACHERS } когда TEXTS , TEACHERS это в свою очередь отношения TEXT , TEACHER (в которых несколько значений), допустим 1 курс может ссылаться на значение TEXT а там несколько учебников, и TEACHER - несколько учителей. Тогда чтоб привести все в 4 нормальную форму - можно привести к НФБК составить отношение { COURSE , TEXT , TEACHER } в которые включатся все комбинации, и явно будет видно избыточность и связанную с ним неудобство, затем разделить на проекции { COURSE , TEXT } , { COURSE , TEACHER } это и получится 4НФ либо 2й способ - сразу разбить на проекции { COURSE , TEACHERS } , { COURSE , TEXTS } и затем привести эти проекции к НФБК, это будет фактически 4НФ. Пятая нормальная форма 5НФ. Есть отношения которые нельзя выполнить декомпозицию на 2 составляющие без потерь, но можно на 3 и более. Допустим есть отношение SPJ {S#, #P, #J} которое можно разбить на 3 проекции {#S, #P}, {#P, #J}, {#J, #S} в результате соединения 3х проекций получится SPJ . Cледует выполнять такую 3-декомпозицию чтоб избавиться в исходной SPJ от аномалий обновления. Переменная отношения R находится в пятой нормальной форме, которую называют иногда проекционно-соединительной нормальной формой ПСНФ тогда и только тогда, когда каждая нетривиальная зависимость соединения в переменной отношения R определяется потенциальным ключом(ключами) R, если соблюдаются условия: Зависимость соединения *{A,B, ..Z} в переменной отношения R является тривиальной тогда и только тогда когда по крайней мере одно из подмножеств A, B, ..Z множества атрибутов является множеством всех атрибутов R. Зависимость соединения *{A,B,..Z} в переменной отношения R определяется потенциальным ключом (ключами) R тогда и только тогда когда каждое из подмножеств А,B..Z множества атрибутов является суперключом для R. Переменная SPJ не находится в 5НФ, поскольку может быть 3-декомпонована. Если переменная отношений находится в 5НФ - она не содержит аномалий. Если переменная отношения находится в 5НФ то единственными в ней являются те зависимости соединения, которые определяются ее потенциальными ключами, и тогда единственными возможными декомпозициями будут декомпозиции, которые основаны на эти потенциальных ключах. (Каждая проекция в подобной декомпозиции будет состоять из одного или нескольких потенциальных ключей в сочетании с доп атрибутами в кол-ве от нуля и больше) Общая схема процедуры нормализации (примечание от меня - предполагается что отношение(таблица) уже находится в 1НФ) Переменную отношения в 1НФ следует разбить на такие проекции, которые позволят исключить все функциональные зависимости, не являющиеся неприводимыми. В результате будет получен набор переменных отношения в 2НФ. Полученные переменные отношения в 2НФ следует разбить на такие проекции, которые позволят исключить все существующие транзитивные функциональные зависимости. В результате будет получен набор переменных отношения в ЗНФ. Полученные переменные отношения в ЗНФ следует разбить на проекции, позволяющие исключить все оставшиеся функциональные зависимости, в которых детерминанты не являются потенциальными ключами. В результате такого приведения будет получен набор переменных отношения в НФБК. Примечание. Правила 1—3 могут быть объединены в одно: \"Исходную переменную отношения следует разбить на проекции, позволяющие исключить все функциональные зависимости, в которых детерминанты не являются потенциальными ключами\". Полученные переменные отношения в НФБК следует разбить на проекции, позво ляющие исключить все многозначные зависимости, которые не являются также функциональными. В результате будет получен набор переменных отношения в 4НФ. Примечание. На практике такие многозначные зависимости обычно исключаются перед выполнением этапов 1-3 (на этапе \"устранения независимых МЗЗ(многознач зависимостей)\") Полученные переменные отношения в 4НФ следует разбить на проекции, позволяющие исключить все зависимости соединения, которые не определяются потенциальными ключами (хотя в данном случае в определение следовало бы добавить фразу \"если удастся их выявить\"). В результате будет получен набор переменных отношения в 5НФ. По поводу приведенных выше правил можно сделать несколько дополнительных замечаний. Процесс разбиения на проекции на каждом этапе должен быть выполнен без потерь и с сохранением зависимостей (там, где это возможно). Обратите внимание, что существует довольно привлекательный набор следующих альтернативных определений НФБК, 4НФ и 5НФ: переменная отношения R находится в НФБК тогда и только тогда, когда каждая функциональная зависимость, удовлетворяемая переменной отношения R, определяется ее потенциальными ключами; переменная отношения R находится в 4НФ тогда и только тогда, когда каждая многозначная зависимость, удовлетворяемая переменной отношения R, определяется ее потенциальными ключами; переменная отношения R находится в 5НФ тогда и только тогда, когда каждая зависимость соединения, удовлетворяемая переменной отношения R, опреде ляется ее потенциальными ключами. Аномалии обновления были вызваны именно теми функциональными зависимостями, многозначными зависимостями или зависимостями соединения, которые не определялись потенциальными ключами. (Подразумевается, что все упомянутые здесь функциональные, многозначные зависимости и зависимости соединения являются нетривиальными.) ОБЩИЕ СВЕДЕНИЯ О ДЕНОРМАЛИЗАЦИИ До сих пор в этой (и предыдущей) главе в основном предполагалось, что полная нормализация вплоть до 5НФ весьма желательна. Но на практике часто можно слышать утверждения, что для достижения высокой производительности системы иногда следует выполнить денормализацию. При этом используются доводы, подобные перечисленным ниже. Полная нормализация приводит к появлению большого количества логически не зависимых переменных отношения (и предполагается, что рассматриваемые переменные отношения являются базовыми). Большое количество логически независимых переменных отношения приводит к появлению большого количества отдельно хранимых физических файлов. Большое количество отдельно хранимых физических файлов приводит к появлению большого количества операций ввода-вывода. Строго говоря, эти доводы, конечно же, не верны, поскольку (как многократно отмечалось в данной книге) в определении реляционной модели нигде не утверждается, что базовые переменные отношения должны находиться во взаимно- однозначном соответствии с хранимыми файлами. Поэтому денормализацию в случае необходимости следует выполнять на уровне хранимых файлов, но не на уровне базовых переменных отношения. Однако в некотором отношении эти доводы все же верны для современных продуктов SQL , поскольку именно в них эти два уровня не разделены в требуемой степени. Общее определение денормализации Напомним, что нормализация переменной отношения R означает ее замену множеством таких проекций Rl, R2, …, Rn, что результатом обратного соединения проекций Rl, R2, …, Rn обязательно будет значение R. Конечной целью нормализации является сокращение степени избыточности данных за счет приведения проекций Rl, R2, …, Rn к максимально высокому уровню нормализации. Теперь можно перейти к определению понятия денормализации. Пусть Rl, R2, Rn является множеством переменных отношения. Тогда денормализацией этих переменных отношения называется такая замена переменных отношения их соединением R, что для всех возможных значений i (где i = 1, …, п) выполнение проекции R по атрибутам Ri обязательно снова приводит к созданию значений Ri. Конечной целью денормализации является увеличение степени избыточности данных за счет приведения переменной отношения R к более низкому уровню нормализации по сравнению с исходными переменными отношения Rl, R2, …, Rn. Точнее, преследуется цель сократить количество соединений, которые потребуется выполнять в приложении на этапе прогона, поскольку (в действительности) некоторые из этих соединений уже выполнены заранее в составе работ по проектированию базы данных. В случае денормализации прежний подход (применявшийся при нормализации), созданный на основании строго научной и логичной теории, заменяется чисто прагматическим и субъективным подходом. Второе очевидное затруднение связано с проблемами избыточности и аномалиями обновления, которые возникают из-за того, что приходится иметь дело с не полностью нормализованными переменными отношения. Самая главная, проблема формулируется следующим образом. (Это относится к \"правильной\" денормализации, т.е. к денормализации, которая выполняется только на физическом уровне, а также к тому типу денормализации, которую иногда приходится осуществлять в современных продуктах SQL .) Когда речь идет о том, что денормализация \"способствует достижению высокой производительности\", фактически подразумевается, что она способствует достижению высокой производительности некоторых конкретных приложений. Любая выбранная физическая структура, которая прекрасно подходит для одних приложений с точки зрения их производительности, может оказаться совершенно непригодной для других. Например, предположим, что каждая базовая переменная отношения отображается на один физически хранимый файл, а каждый хранимый файл состоит из физически смежного набора хранимых записей, по одной для каждого кортежа соответствующей переменной отношения. Транзакции Транзакция — это логическая единица работы, а также единица восстановления Свойства ACID транзакций Заключение, что транзакции обладают (или должны обладать!) четырьмя важными свойствами: неразрывностью (atomicity), правильностью6 (correctness), изолированностью (isolation) и устойчивостью (durability). Этот набор свойств принято называть свойствами ACID (по первым буквам их английских названий). Неразрывность. Транзакции неразрывны (выполняются по принципу \"все или ни чего\"). Правильность. Транзакции преобразуют базу данных из одного правильного со стояния в другое; при этом правильность не обязательно должна обеспечиваться на всех промежуточных этапах. Изолированность. Транзакции изолированы одна от другой. Таким образом, даже если будет запущено множество транзакций, работающих параллельно, результаты любых операций обновления, выполняемых отдельной транзакцией, будут скрыты от всех остальных транзакций до тех пор, пока эта транзакция не будет зафиксиро вана. Иначе говоря, для любых отдельных транзакций А и В справедливо следую щее утверждение: транзакция А сможет получить результаты выполненных тран закцией в обновлений только после фиксации транзакции в, а транзакция в смо жет получить результаты выполненных транзакцией А обновлений только после фиксации транзакции А. Устойчивость. После того как транзакция зафиксирована, выполненные ею обновления сохраняются в базе данных на постоянной основе, даже если в дальнейшем произойдет аварийный останов системы Выводы: Общее назначение процесса нормализации заключается в следующем: * исключение некоторых типов избыточности; * устранение некоторых аномалий обновления; * разработка проекта базы данных, который является достаточно \"качествен ным\" представлением реального мира, интуитивно понятен и может служить хорошей основой для последующего расширения; * упрощение процедуры применения необходимых ограничений целостности. Понятия зависимости и дальнейшей нормализации по своему характеру являются семантическими, т.е. они связаны со смыслом данных, тогда как реляционная алгебра и реляционное исчисление, а также построенные на их основе языки наподобие SQL , наоборот, имеют дело со значениями данных и не требуют (да и не могут требовать) выполнения нормализации выше первого уровня. Рекомендации по выполнению дальнейшей нормализации должны рассматриваться прежде всего как методика, позволяющая разработчику базы данных (и, следовательно, ее пользователю) выразить определенную часть семантики реального мира (пусть даже небольшую) в простой и понятной форме. Сам я практически наглядно подтвердил себе, что 3НФ вполне достаточно, а возможно даже и 2НФ. Так как при 3НФ уже приходится для получения информации обращаться к нескольким таблицам. Пока пожалуй на этом остановлюсь, но чувствую что время от времени придется возможно перечитывать главы из книги К.Дж. Дейта \"Введение в системы баз данных\". Ресурсы: Введение в системы баз данных К.Дж.Дейт SQL Tutorial SQL для простых смертных Описание основных приемов нормализации базы данных Проектирование базы данных MySQL www.postgresqltutorial.com tutorialspoint.com https://yuml.me dbdesigner.net Нормализация отношений. Шесть нормальных форм","tags":"Blog","url":"https://ruthkraus.github.io/2017/07/db-theory-high-forms.html","loc":"https://ruthkraus.github.io/2017/07/db-theory-high-forms.html"},{"title":"Процедура нормализации данных и нормальные формы данных (2НФ).","text":"Итак пришло время привести данные, которые мы привели к 1НФ, ко 2НФ. Само понятие 2НФ можно процитировать из книги Дж. Дейта, как: 2НФ - переменная отношения находится во 2нф тогда и только тогда, когда она находится в первой нф и каждый неключевой атрибут неприводимо зависит от ее первичного ключа.(предполагается наличие 1 потенциального ключа который является первичным ключом) Первый этап нормализации (подразумевается что отношения уже в 1НФ) Всякую переменную отношения которая находится в 1НФ, но не находится во 2НФ всегда можно свести к эквивалентному множеству отношений находящихся во 2НФ. Этот процесс заключается в замене переменной отношения 1НФ подходящим набором проекций, эквивалентных исходной переменной отношения , в том смысле что ее всегда можно будет восстановить путем соединения данных проекций. Если есть R {A,B,C,D} PRIMARY KEY {A,B} (предположим что А зависит от D A -> D), тогда процедура нормализации состоит в замене этой R двумя проекциями R1 {A, D} PRIMARY KEY {A} R2 {A, B, C} PRIMARY KEY {A,B} FOREIGN KEY {A} REFERENCES R1 получается R2 будет иметь атрибут А как внешний ключ ссылаясь на первичный ключ A таблицы R1 и переменная отношения R может быть восстановлена посредством соединения переменных отношения R1 R2 по внешнему ключу и соответствующему ему первичному ключу этих переменных отношения. Своими словами, если у нас в таблице есть столбец который явно зависит от первичного ключа, его следует выделить в отдельную таблицу, где будет первичный ключ и этот столбец, а в исходной таблице бывший первичный ключ станет внешним. (фактически это приводит к удалению дубликатов в строках и разделению данных которые зависят от одной из частей составного первичного ключа, фактически разделяется на отдельные отношения в которых отдельная часть составного первичного ключа будет являться первичным ключом а, второе отношение будет иметь составной первичный ключ, в котором выделенная часть предыдущего составного первичного ключа будет внешним ключом по отношению к первичному ключу отделенного отношения) Напомним к чему мы пришли приведя данные в 1НФ: haircolors = # ALTER TABLE customers DROP COLUMN address_old ; ALTER TABLE haircolors = # select * from customers ; id | firstname | lastname | phonenumber | manufacturer | product_name | dateorder | price | qty | salon_name | address ----+-----------+----------+--------------+--------------+-----------------------+---------------------+------------+-----+------------+--------- 5 | Денис | Петров | + 79784567897 | Matrix | Краска для волос | 2017 - 07 - 03 12 : 15 : 01 | 899.01 руб | 3 | 1 | 1 6 | Денис | Петров | + 79784567897 | Matrix | Краска для волос | 2017 - 07 - 03 12 : 15 : 01 | 899.01 руб | 3 | 2 | 1 7 | Денис | Петров | + 79784567897 | Matrix | Краска для волос | 2017 - 07 - 03 12 : 15 : 01 | 899.01 руб | 3 | 4 | 1 8 | Денис | Петров | + 79784567897 | Loreal | Краска для волос | 2017 - 07 - 03 12 : 16 : 01 | 599.12 руб | 2 | 1 | 1 9 | Денис | Петров | + 79784567897 | Loreal | Краска для волос | 2017 - 07 - 03 12 : 16 : 01 | 599.12 руб | 2 | 2 | 1 10 | Денис | Петров | + 79784567897 | Loreal | Краска для волос | 2017 - 07 - 03 12 : 16 : 01 | 599.12 руб | 2 | 4 | 1 11 | Юлия | Бабкина | + 79784168585 | Blond | Краска для волос | 2017 - 07 - 02 11 : 01 : 01 | 299.12 руб | 12 | 3 | 2 12 | Юлия | Бабкина | + 79784168585 | Blond | Краска для волос | 2017 - 07 - 02 11 : 01 : 01 | 299.12 руб | 12 | 4 | 2 13 | Юлия | Бабкина | + 79784168585 | Blond | Краска для волос | 2017 - 07 - 02 11 : 01 : 01 | 299.12 руб | 12 | 5 | 2 14 | Юлия | Бабкина | + 79784168585 | Союз | Полотенца одноразовые | 2017 - 07 - 02 11 : 01 : 01 | 199.12 руб | 120 | 3 | 2 15 | Юлия | Бабкина | + 79784168585 | Союз | Полотенца одноразовые | 2017 - 07 - 02 11 : 01 : 01 | 199.12 руб | 120 | 4 | 2 16 | Юлия | Бабкина | + 79784168585 | Союз | Полотенца одноразовые | 2017 - 07 - 02 11 : 01 : 01 | 199.12 руб | 120 | 5 | 2 ( 12 rows ) haircolors = # select * from salon; salon_id | salon_name ----------+------------ 1 | Е - Студия 2 | Ле - туаль 3 | UpDo 4 | ViVa 5 | Diana ( 5 rows ) haircolors = # select * from address ; id | city | building | flat_no | street | zip_code ----+-------------+----------+---------+-------------------------+---------- 1 | Севастополь | 77 | 54 | ул . Александра Косарева | 299006 2 | Севастополь | 1 | 55 | ул . Кесаева | 299003 ( 2 rows ) Явно видно, что имя-фамилия покупателей образуют уникальный ключ и существует связь с полем address , создадим таблицу PERSON в ней создадим поле address , которое является внешним ключом ссылающимся на первичный ключ таблицы ADDRESS (id) и свяжет таким образом покупателя с адресом (person.address( FK )) -> address.id( PK ). Заполним таблицу данными: CREATE TABLE PERSON ( PERSON_ID INT PRIMARY KEY , FIRSTNAME VARCHAR ( 128 ) NOT NULL , LASTNAME VARCHAR ( 128 ) NOT NULL , PHONENUMBER VARCHAR ( 20 ) NOT NULL , ADDRESS INT , CONSTRAINT fk_address_id FOREIGN KEY ( ADDRESS ) REFERENCES address ( id ) ); INSERT INTO PERSON ( PERSON_ID , FIRSTNAME , LASTNAME , PHONENUMBER , ADDRESS ) VALUES ( 1 , 'Денис' , 'Петров' , '+79784567897' , 1 ); INSERT INTO PERSON ( PERSON_ID , FIRSTNAME , LASTNAME , PHONENUMBER , ADDRESS ) VALUES ( 2 , 'Юлия' , 'Бабкина' , '+79784168585' , 2 ); не забудем, для целостности данных добавим уникальность полю address ведь у нас 1 покупатель может иметь только 1 уникальный адрес, мы условились что разные покупатели не могут иметь один и тот же адрес: ALTER TABLE person ADD UNIQUE ( address ); haircolors = # \\d person Table \"public.person\" Column | Type | Modifiers -------------+------------------------+----------- person_id | integer | not null firstname | character varying ( 128 ) | not null lastname | character varying ( 128 ) | not null phonenumber | character varying ( 20 ) | not null address | integer | Indexes : \"person_pkey\" PRIMARY KEY , btree ( person_id ) \"person_address_key\" UNIQUE CONSTRAINT , btree ( address ) Foreign - key constraints : \"fk_address_id\" FOREIGN KEY ( address ) REFERENCES address ( id ) Referenced by : TABLE \"customers\" CONSTRAINT \"fk_person_id\" FOREIGN KEY ( person_id ) REFERENCES person ( person_id ) haircolors = # select * from person ; person_id | firstname | lastname | phonenumber | address -----------+-----------+----------+--------------+--------- 1 | Денис | Петров | + 79784567897 | 1 2 | Юлия | Бабкина | + 79784168585 | 2 ( 2 rows ) Теперь при попытке назначить один и тот же адрес 2м разным пользователям система откажет в операции и вызовет исключение, попробуем установить Юлии Бабкиной такой же адрес как Денису Петрову: haircolors = # UPDATE person SET address=1 WHERE person_id=2; ERROR : duplicate key value violates unique constraint \"person_address_key\" DETAIL : Key ( address ) = ( 1 ) already exists . Единственое, ошибочка вышла, лучше переименум поле address в address_id чтоб отражался смысл ALTER TABLE person RENAME COLUMN address TO address_id ; Таблица примет вид haircolors = # \\d person Table \"public.person\" Column | Type | Modifiers -------------+------------------------+----------- person_id | integer | not null firstname | character varying ( 128 ) | not null lastname | character varying ( 128 ) | not null phonenumber | character varying ( 20 ) | not null address_id | integer | Indexes : \"person_pkey\" PRIMARY KEY , btree ( person_id ) \"person_address_key\" UNIQUE CONSTRAINT , btree ( address_id ) Foreign - key constraints : \"fk_address_id\" FOREIGN KEY ( address_id ) REFERENCES address ( id ) Referenced by : TABLE \"partner\" CONSTRAINT \"partner_person_id_fkey\" FOREIGN KEY ( person_id ) REFERENCES person ( person_id ) c данными: haircolors = # select * from person ; person_id | firstname | lastname | phonenumber | address_id -----------+-----------+----------+--------------+------------ 1 | Денис | Петров | + 79784567897 | 1 2 | Юлия | Бабкина | + 79784168585 | 2 ( 2 rows ) Таким образом мы выразили связь ОДИН К ОДНОМУ ( ONE TO ONE ), используя внешний ключ и уникальный индекс. Можно было также в модели ADDRESS добавить поле person_id, сделать его внешним ключом и добавить уникальность. (т.е. фактически то же самое, но в обратную сторону) Пока будем считать что мы сделали равнозначный вариант, но предполагаю что в будущем не исключено что можно сделать обратное, например для некоего удобства. Теперь нашу исходную таблицу CUSTOMERS можно представить так, мы добавим столбец person_id и по нему все также мы можем узнать адрес покупателя, т.е. информацию мы не теряем, это самый главный принцип, мы не должны в результате нормализации потерять часть информации. Т.е. можем убрать столбцы firstname, lastname, phonenumber, address и все равно можем узнать имя-фамилию, телефон, адрес покупателя. ALTER TABLE CUSTOMERS DROP COLUMN firstname ; ALTER TABLE CUSTOMERS DROP COLUMN lastname ; ALTER TABLE CUSTOMERS DROP COLUMN phonenumber ; ALTER TABLE CUSTOMERS DROP COLUMN address ; ALTER TABLE customers ADD COLUMN person_id INT ; ALTER TABLE customers ADD CONSTRAINT fk_person_id FOREIGN KEY ( person_id ) REFERENCES person ( person_id ); UPDATE customers SET person_id = 1 WHERE id IN ( 5 , 6 , 7 , 8 , 9 , 10 ); UPDATE customers SET person_id = 2 WHERE id NOT IN ( 5 , 6 , 7 , 8 , 9 , 10 ); haircolors=# select * from customers ; id | manufacturer | product_name | dateorder | price | qty | salon_name | person_id ----+--------------+-----------------------+---------------------+------------+-----+------------+----------- 5 | Matrix | Краска для волос | 2017-07-03 12:15:01 | 899.01 руб | 3 | 1 | 1 6 | Matrix | Краска для волос | 2017-07-03 12:15:01 | 899.01 руб | 3 | 2 | 1 7 | Matrix | Краска для волос | 2017-07-03 12:15:01 | 899.01 руб | 3 | 4 | 1 8 | Loreal | Краска для волос | 2017-07-03 12:16:01 | 599.12 руб | 2 | 1 | 1 9 | Loreal | Краска для волос | 2017-07-03 12:16:01 | 599.12 руб | 2 | 2 | 1 10 | Loreal | Краска для волос | 2017-07-03 12:16:01 | 599.12 руб | 2 | 4 | 1 11 | Blond | Краска для волос | 2017-07-02 11:01:01 | 299.12 руб | 12 | 3 | 2 12 | Blond | Краска для волос | 2017-07-02 11:01:01 | 299.12 руб | 12 | 4 | 2 13 | Blond | Краска для волос | 2017-07-02 11:01:01 | 299.12 руб | 12 | 5 | 2 14 | Союз | Полотенца одноразовые | 2017-07-02 11:01:01 | 199.12 руб | 120 | 3 | 2 15 | Союз | Полотенца одноразовые | 2017-07-02 11:01:01 | 199.12 руб | 120 | 4 | 2 16 | Союз | Полотенца одноразовые | 2017-07-02 11:01:01 | 199.12 руб | 120 | 5 | 2 (12 rows) Теперь наша таблица CUSTOMERS все больше напоминает список заказов которые делает покупатель, который представлен внешним ключом person_id. Продолжим, явно у нас есть связь между производителем и продуктом, т.е. продукт явно должен быть кем то произведен, причем продукт может производиться разными производителями. Правило приведения ко 2НФ советует сделать таблицы для столбцов с повторяющимися значениями. Так и поступим, создадим таблицу MANUFACTURER : CREATE TABLE MANUFACTURER ( MANUFACTURER_ID INT PRIMARY KEY , NAME VARCHAR ( 256 ) NOT NULL ); INSERT INTO MANUFACTURER ( MANUFACTURER_ID , NAME ) VALUES ( 1 , 'Matrix' ); INSERT INTO MANUFACTURER ( MANUFACTURER_ID , NAME ) VALUES ( 2 , 'Loreal' ); INSERT INTO MANUFACTURER ( MANUFACTURER_ID , NAME ) VALUES ( 3 , 'Blond' ); INSERT INTO MANUFACTURER ( MANUFACTURER_ID , NAME ) VALUES ( 4 , 'Союз' ); haircolors = # \\d manufacturer Table \"public.manufacturer\" Column | Type | Modifiers -----------------+------------------------+----------- manufacturer_id | integer | not null name | character varying ( 256 ) | not null Indexes : \"manufacturer_pkey\" PRIMARY KEY , btree ( manufacturer_id ) haircolors = # select * from manufacturer ; manufacturer_id | name -----------------+-------- 1 | Matrix 2 | Loreal 3 | Blond 4 | Союз ( 4 rows ) А теперь создадим таблицу PRODUCT , здесь явно видна связь между названием продукта/товара, производителем и ценой. Фактически атрибуты NAME и MANUFACTURER_ID образуют первичный ключ, но я добавлю отдельный первичный ключ для удобства - PRODUCT_ID. Это некоторая избыточность с теоретической точки зрения, но мне кажется что с таким подходом работать с данными удобнее. Теоретически я не должен добавлять PRODUCT_ID, уникальность уже обеспечивает связка название товара - производитель, но в таком случае у нас будет сложный первичный ключ (первичный ключ образованный значениями 2х столбцов). CREATE TABLE PRODUCT ( PRODUCT_ID INT PRIMARY KEY , NAME VARCHAR ( 256 ), MANUFACTURER_ID INT REFERENCES manufacturer ( manufacturer_id ), PRICE MONEY ); INSERT INTO PRODUCT ( PRODUCT_ID , NAME , MANUFACTURER_ID , PRICE ) VALUES ( 1 , 'Краска для волос' , 1 , 899.01 ); INSERT INTO PRODUCT ( PRODUCT_ID , NAME , MANUFACTURER_ID , PRICE ) VALUES ( 2 , 'Краска для волос' , 2 , 599.12 ); INSERT INTO PRODUCT ( PRODUCT_ID , NAME , MANUFACTURER_ID , PRICE ) VALUES ( 3 , 'Краска для волос' , 3 , 299.12 ); INSERT INTO PRODUCT ( PRODUCT_ID , NAME , MANUFACTURER_ID , PRICE ) VALUES ( 4 , 'Полотенца одноразовые' , 4 , 199.12 ); haircolors = # \\d product Table \"public.product\" Column | Type | Modifiers -----------------+------------------------+----------- product_id | integer | not null name | character varying ( 256 ) | manufacturer_id | integer | price | money | Indexes : \"product_pkey\" PRIMARY KEY , btree ( product_id ) Foreign - key constraints : \"product_manufacturer_id_fkey\" FOREIGN KEY ( manufacturer_id ) REFERENCES manufacturer ( manufacturer_id ) haircolors = # select * from product ; product_id | name | manufacturer_id | price ------------+-----------------------+-----------------+------------ 1 | Краска для волос | 1 | 899.01 руб 2 | Краска для волос | 2 | 599.12 руб 3 | Краска для волос | 3 | 299.12 руб 4 | Полотенца одноразовые | 4 | 199.12 руб ( 4 rows ) Теперь мы можем сослаться на product_id таблицы PRODUCT в нашей изначальной таблице чтобы обозначить что покупают покупатели. Добавим столбец product_id в таблицу CUSTOMERS , как внешний ключ ссылающийся на значение поля таблицы PRODUCT .PRODUCT_ID ALTER TABLE customers ADD COLUMN product_id INT REFERENCES product ( product_id ); haircolors=# select * from customers ; id | manufacturer | product_name | dateorder | price | qty | salon_name | person_id | product_id ----+--------------+-----------------------+---------------------+------------+-----+------------+-----------+------------ 5 | Matrix | Краска для волос | 2017-07-03 12:15:01 | 899.01 руб | 3 | 1 | 1 | 6 | Matrix | Краска для волос | 2017-07-03 12:15:01 | 899.01 руб | 3 | 2 | 1 | 7 | Matrix | Краска для волос | 2017-07-03 12:15:01 | 899.01 руб | 3 | 4 | 1 | 8 | Loreal | Краска для волос | 2017-07-03 12:16:01 | 599.12 руб | 2 | 1 | 1 | 9 | Loreal | Краска для волос | 2017-07-03 12:16:01 | 599.12 руб | 2 | 2 | 1 | 10 | Loreal | Краска для волос | 2017-07-03 12:16:01 | 599.12 руб | 2 | 4 | 1 | 11 | Blond | Краска для волос | 2017-07-02 11:01:01 | 299.12 руб | 12 | 3 | 2 | 12 | Blond | Краска для волос | 2017-07-02 11:01:01 | 299.12 руб | 12 | 4 | 2 | 13 | Blond | Краска для волос | 2017-07-02 11:01:01 | 299.12 руб | 12 | 5 | 2 | 14 | Союз | Полотенца одноразовые | 2017-07-02 11:01:01 | 199.12 руб | 120 | 3 | 2 | 15 | Союз | Полотенца одноразовые | 2017-07-02 11:01:01 | 199.12 руб | 120 | 4 | 2 | 16 | Союз | Полотенца одноразовые | 2017-07-02 11:01:01 | 199.12 руб | 120 | 5 | 2 | (12 rows) Подставим значения соответствующих product.product_id и затем удалим столбцы manufacturer, product_name, price UPDATE customers SET product_id = 1 WHERE id in ( 5 , 6 , 7 ); UPDATE customers SET product_id = 2 WHERE id in ( 8 , 9 , 10 ); UPDATE customers SET product_id = 3 WHERE id in ( 11 , 12 , 13 ); UPDATE customers SET product_id = 4 WHERE id in ( 14 , 15 , 16 ); ALTER TABLE customers DROP COLUMN manufacturer ; ALTER TABLE customers DROP COLUMN product_name ; ALTER TABLE customers DROP COLUMN price ; Переименуем неудачно названный столбец salon_name, так как он означает суть salon_id, мы можем вычислить по нему salon_name, но в таблице мы указываем именно salon_id: ALTER TABLE customers RENAME COLUMN salon_name TO salon_id ; Можно переименовать ограничение ALTER TABLE customers RENAME CONSTRAINT fk_salon_name TO fk_salon_id ; haircolors=# select * from customers ; id | dateorder | qty | salon_id | person_id | product_id ----+---------------------+-----+----------+-----------+------------ 5 | 2017-07-03 12:15:01 | 3 | 1 | 1 | 1 6 | 2017-07-03 12:15:01 | 3 | 2 | 1 | 1 7 | 2017-07-03 12:15:01 | 3 | 4 | 1 | 1 8 | 2017-07-03 12:16:01 | 2 | 1 | 1 | 2 9 | 2017-07-03 12:16:01 | 2 | 2 | 1 | 2 10 | 2017-07-03 12:16:01 | 2 | 4 | 1 | 2 11 | 2017-07-02 11:01:01 | 12 | 3 | 2 | 3 12 | 2017-07-02 11:01:01 | 12 | 4 | 2 | 3 13 | 2017-07-02 11:01:01 | 12 | 5 | 2 | 3 14 | 2017-07-02 11:01:01 | 120 | 3 | 2 | 4 15 | 2017-07-02 11:01:01 | 120 | 4 | 2 | 4 16 | 2017-07-02 11:01:01 | 120 | 5 | 2 | 4 (12 rows) Также я хотел бы переименовать таблицу СUSTOMERS потому что она отражает скорее заказы чем покупателей, переименуем в ORDERS (я изначально неправильно назвал исходную таблицу и вот в результате приведения проблема обозначилась очень явно, когда убрали лишние по смыслу данные которые сбили меня с толку вначале): link ALTER TABLE customers RENAME TO orders ; haircolors = # \\d orders Table \"public.orders\" Column | Type | Modifiers ------------+-----------------------------+----------- id | integer | not null dateorder | timestamp without time zone | not null qty | integer | not null salon_id | integer | person_id | integer | product_id | integer | Indexes : \"customers_pkey\" PRIMARY KEY , btree ( id ) Foreign - key constraints : \"customers_product_id_fkey\" FOREIGN KEY ( product_id ) REFERENCES product ( product_id ) \"fk_person_id\" FOREIGN KEY ( person_id ) REFERENCES person ( person_id ) \"fk_salon_id\" FOREIGN KEY ( salon_id ) REFERENCES salon ( salon_id ) Переименуем ограничения, так как после переименования у нас остались названия на более не существующее имя CUSTOMERS : ALTER TABLE orders RENAME CONSTRAINT customers_pkey TO orders_pkey ; ALTER TABLE orders RENAME CONSTRAINT customers_product_id_fkey TO orders_product_id_fkey ; haircolors = # \\d orders Table \"public.orders\" Column | Type | Modifiers ------------+-----------------------------+----------- id | integer | not null dateorder | timestamp without time zone | not null qty | integer | not null salon_id | integer | person_id | integer | product_id | integer | Indexes : \"orders_pkey\" PRIMARY KEY , btree ( id ) Foreign - key constraints : \"fk_person_id\" FOREIGN KEY ( person_id ) REFERENCES person ( person_id ) \"fk_salon_id\" FOREIGN KEY ( salon_id ) REFERENCES salon ( salon_id ) \"orders_product_id_fkey\" FOREIGN KEY ( product_id ) REFERENCES product ( product_id ) В результате преобразований получилась таблица ORDER которая все так же отражает покупки покупателей, и мы по прежнему можем узнать детали относящиеся к покупателю, цену отдельного товара и название производителя. haircolors=# select * from orders ; id | dateorder | qty | salon_id | person_id | product_id ----+---------------------+-----+----------+-----------+------------ 5 | 2017-07-03 12:15:01 | 3 | 1 | 1 | 1 6 | 2017-07-03 12:15:01 | 3 | 2 | 1 | 1 7 | 2017-07-03 12:15:01 | 3 | 4 | 1 | 1 8 | 2017-07-03 12:16:01 | 2 | 1 | 1 | 2 9 | 2017-07-03 12:16:01 | 2 | 2 | 1 | 2 10 | 2017-07-03 12:16:01 | 2 | 4 | 1 | 2 11 | 2017-07-02 11:01:01 | 12 | 3 | 2 | 3 12 | 2017-07-02 11:01:01 | 12 | 4 | 2 | 3 13 | 2017-07-02 11:01:01 | 12 | 5 | 2 | 3 14 | 2017-07-02 11:01:01 | 120 | 3 | 2 | 4 15 | 2017-07-02 11:01:01 | 120 | 4 | 2 | 4 16 | 2017-07-02 11:01:01 | 120 | 5 | 2 | 4 (12 rows) Смотрим, у нас явно связь и повторы между person_id и salon_id, вынесем ее в таблицу которую назовем PARTNER и действительно, у нас покупатели являются партнерами-поставщиками для салонов. CREATE TABLE PARTNER ( PARTNER_ID SERIAL PRIMARY KEY , PERSON_ID INT REFERENCES PERSON ( PERSON_ID ), SALON_ID INT REFERENCES SALON ( SALON_ID ) ); INSERT INTO PARTNER ( PERSON_ID , SALON_ID ) VALUES ( 1 , 1 ); INSERT INTO PARTNER ( PERSON_ID , SALON_ID ) VALUES ( 1 , 2 ); INSERT INTO PARTNER ( PERSON_ID , SALON_ID ) VALUES ( 1 , 4 ); INSERT INTO PARTNER ( PERSON_ID , SALON_ID ) VALUES ( 2 , 3 ); INSERT INTO PARTNER ( PERSON_ID , SALON_ID ) VALUES ( 2 , 4 ); INSERT INTO PARTNER ( PERSON_ID , SALON_ID ) VALUES ( 2 , 5 ); haircolors = # \\d partner Table \"public.partner\" Column | Type | Modifiers ------------+---------+-------------------------------------------------------------- partner_id | integer | not null default nextval ( 'partner_partner_id_seq' :: regclass ) person_id | integer | salon_id | integer | Indexes : \"partner_pkey\" PRIMARY KEY , btree ( partner_id ) Foreign - key constraints : \"partner_person_id_fkey\" FOREIGN KEY ( person_id ) REFERENCES person ( person_id ) \"partner_salon_id_fkey\" FOREIGN KEY ( salon_id ) REFERENCES salon ( salon_id ) haircolors=# select * from partner; partner_id | person_id | salon_id ------------+-----------+---------- 1 | 1 | 1 2 | 1 | 2 3 | 1 | 4 4 | 2 | 3 5 | 2 | 4 6 | 2 | 5 (6 rows) Получилось мы еще упростили нашу таблицу ORDERS , теперь возможно добавить партнера (как связь покупатель-салон, допустим это может означать, что салон начал работать с новым поставщиком) и мы можем это сделать, даже если покупатель не совершил ни одного заказа, чего раньше мы сделать просто не могли, так как для выражения связи того что какой то покупатель поставляет гипотетически что то в какой то салон, нам было необходимо чтоб этот покупатель совершил заказ. Теперь у нас могут быть партнеры не совершившие ни одного заказа ! Вот одно из положительных качеств нормализации. Также можно удалить столбцы salon_id, person_id из таблицы ORDERS . ALTER TABLE orders ADD COLUMN partner_id INT REFERENCES partner ( partner_id ); UPDATE orders SET partner_id = 1 WHERE id IN ( 5 , 8 ); UPDATE orders SET partner_id = 2 WHERE id IN ( 6 , 9 ); UPDATE orders SET partner_id = 3 WHERE id IN ( 7 , 10 ); UPDATE orders SET partner_id = 4 WHERE id IN ( 11 , 14 ); UPDATE orders SET partner_id = 5 WHERE id IN ( 12 , 15 ); UPDATE orders SET partner_id = 6 WHERE id IN ( 13 , 16 ); ALTER TABLE orders DROP COLUMN salon_id ; ALTER TABLE orders DROP COLUMN person_id ; haircolors=# select * from orders order by id ; id | dateorder | qty | product_id | partner_id ----+---------------------+-----+------------+------------ 5 | 2017-07-03 12:15:01 | 3 | 1 | 1 6 | 2017-07-03 12:15:01 | 3 | 1 | 2 7 | 2017-07-03 12:15:01 | 3 | 1 | 3 8 | 2017-07-03 12:16:01 | 2 | 2 | 1 9 | 2017-07-03 12:16:01 | 2 | 2 | 2 10 | 2017-07-03 12:16:01 | 2 | 2 | 3 11 | 2017-07-02 11:01:01 | 12 | 3 | 4 12 | 2017-07-02 11:01:01 | 12 | 3 | 5 13 | 2017-07-02 11:01:01 | 12 | 3 | 6 14 | 2017-07-02 11:01:01 | 120 | 4 | 4 15 | 2017-07-02 11:01:01 | 120 | 4 | 5 16 | 2017-07-02 11:01:01 | 120 | 4 | 6 (12 rows) Как видим тенденция такая, с каждым шагом появляется все больше таблиц, а изначальная таблица вырождается в описание связей. Управлять целостностью проще, данные разделяются все больше по смыслу, но общую картину теперь возможно немного сложнее представить. У нас присутствует дублирование на первый взгляд dateorder, qty, но это обусловлено тем что мы изначально имели перечисление салонов в столбце salon_name и получается, что покупатели как бы купили в одно и то же время разные товары сразу для нескольких салонов, т.е. по смыслу здесь может быть и разное на самом деле время, то же самое относится к столбцу qty . Но, и здесь можно убрать дублирование создадим таблицу ORDER_DETAILS CREATE TABLE ORDER_DETAILS ( ORDER_DETAILS_ID SERIAL PRIMARY KEY , DATEORDER TIMESTAMP , QTY INT ); INSERT INTO ORDER_DETAILS ( DATEORDER , QTY ) VALUES ( '2017-07-03 12:15:01' , 3 ); INSERT INTO ORDER_DETAILS ( DATEORDER , QTY ) VALUES ( '2017-07-03 12:16:01' , 2 ); INSERT INTO ORDER_DETAILS ( DATEORDER , QTY ) VALUES ( '2017-07-02 11:01:01' , 12 ); INSERT INTO ORDER_DETAILS ( DATEORDER , QTY ) VALUES ( '2017-07-02 11:01:01' , 120 ); haircolors=# select * from order_details; order_details_id | dateorder | qty ------------------+---------------------+----- 1 | 2017-07-03 12:15:01 | 3 2 | 2017-07-03 12:16:01 | 2 3 | 2017-07-02 11:01:01 | 12 4 | 2017-07-02 11:01:01 | 120 (4 rows) Сошлемся на эти данные из таблицы ORDERS : ALTER TABLE orders ADD COLUMN ORDER_DETAILS_ID INT REFERENCES order_details ( order_details_id ); UPDATE orders SET order_details_id = 1 WHERE id IN ( 5 , 6 , 7 ); UPDATE orders SET order_details_id = 2 WHERE id IN ( 8 , 9 , 10 ); UPDATE orders SET order_details_id = 3 WHERE id IN ( 11 , 12 , 13 ); UPDATE orders SET order_details_id = 4 WHERE id IN ( 14 , 15 , 16 ); И теперь можно удалить столбцы dateorder, qty: ALTER TABLE orders DROP COLUMN dateorder ; ALTER TABLE orders DROP COLUMN qty ; Все, на этом можно остановиться, у нас данные находятся, во 2НФ, мы избавились от дубликатов в колонках, и теперь таблица ORDERS содержит уникальный первичный ключ id отражающий номер покупки, а также включает в себя отображение связей кто ( partner_id ), какой именно продукт ( product_id ) купил и когда ( order_details_id ). Эти три значения отражают уникальность каждой покупки, в принципе можно даже отказаться от параметра id и использовать первичный сложный ключ из трех столбцов, но по моему мнению это неудобно, я хочу иметь номер заказа. haircolors=# select * from orders; id | product_id | partner_id | order_details_id ----+------------+------------+------------------ 5 | 1 | 1 | 1 6 | 1 | 2 | 1 7 | 1 | 3 | 1 8 | 2 | 1 | 2 9 | 2 | 2 | 2 10 | 2 | 3 | 2 11 | 3 | 4 | 3 12 | 3 | 5 | 3 13 | 3 | 6 | 3 14 | 4 | 4 | 4 15 | 4 | 5 | 4 16 | 4 | 6 | 4 (12 rows) В результате преобразований у нас получилось несколько таблиц, мы использовали связи различных типов, такие как ОДИН К ОДНОМУ , ОДИН КО МНОГИМ , МНОГИЕ КО МНОГИМ . Мое лично субьективное мнение, что формы в которой находится база данных сейчас с практической точки зрения достаточно. В следующей статье я возможно попробую привести некоторые данные в 3НФ, а также нарисую схему связей нашей базы данных. P.S. Я буду очень рад если кто то, прочитав заметку, укажет на мои ошибки. Я честно старался принимать логичные решения и эволюционировал связи без всяческих \"подгонок\". Конечно же я мог ошибиться логически. Данная статья не является учебником для кого-то, и написана мной для меня в первую очередь. Для себя с некоторым удивлением замечаю как простая база в 4 записи превращается во множество таблиц со связями. Советую людям которым интересно взять свой пример и проделать похожее, как по мне это интересно и полезно ;-)","tags":"Blog","url":"https://ruthkraus.github.io/2017/07/db-theory-2nf.html","loc":"https://ruthkraus.github.io/2017/07/db-theory-2nf.html"},{"title":"Процедура нормализации данных и нормальные формы данных (НФБК, 3НФ).","text":"Продолжим нормализацию и попробуем привести некоторые таблицы к 3НФ, для начала приведу определение 3НФ, НФБК а также те определения и примеры которые считаю важными (далее цитаты из книги Дж. Дейта): Третья нормальная форма 3НФ - переменная отношения находится в 3нф тогда , когда каждый кортеж состоит из значений первичного ключа и множества независимых атрибутов (неключевых), в кол-ве от нуля и более некоторым образом описывающих сущность. (в определении передполагается наличие только одного потенциального ключа, который является первичным ключом) Переменная отношения находится в 3нф тогда , когда она находится во 2й нф и ни один неключевой атрибут не является транзитивно зависимым от ее первичного ключа (под эти подразумевается отсутствие в переменной отношения транзитивных зависимостей). Это означает что в ней отсутствуют какие либо взаимные зависимости в указанном выше смысле Второй этап нормализации состоит в создании проекций для устранения транзитивных зависимостей (когда одни данные могут быть получены через другие) Пусть есть * R {A,B,C} PRIMARY KEY {A} (предположим есть зависимость B->C ( CITY -> STATUS )) Процедура нормализации передусматривает замену переменной отношения R следующими двумя проекциями R1 и R2 * R1 {B, C} PRIMARY KEY {B} * R2 {A, B} PRIMARY KEY {A} FOREIGN KEY {B} REFERENCES R1 Переменная отношения R может быть восстановлена посредством соединения переменных отношения R1 и R2 по внешнему ключу и соотв ему первичному ключу этих переменных отношения. Нужно стремиться к независимости отдельных проекций, т.е R1 должна не зависеть от R2 (мы могли бы разделить R1{A,B}, R2{A,C}, но в таком случае это были бы не независмые отношенияб так как мы потеряем зависимость что B -> C) Нет смысла обязательно проводить декомпозицию до получения атомарных проекций (проекций которые уже не могут быть подвергнуты декомпозиции) Декомпозиция должна обеспечивать сохранение зависимостей !!! Нормальная форма Бойса-Кодда НФБК (более строгая чем 3НФ, для случаев составных ключей) Она определяется для данных для которых верны следующие условия: переменная отношения имеет 2 и больше потенциальных ключа, таких что Эти ключи являются составными Два или больше составных ключей перекрываются, т.е. имеют 1 общий атрибут. Переменная отношения находится в нормальной форме Бойса-Кодда тогда и только тогда, когда детерминанты всех ее функц зависимостей являются потенциальными ключами. НФБК позволяют избавиться от проблем присущим в 3НФ (может присутствовать некоторая избыточность, которая приводит к проблемам insert/delete/update) и плюс то что определение не содержит ссылок на 1 и 2 нф Например, как показано в книге, пример: SP {S#, SNAME , P#, QTY } ключи {S#, P#} и { SNAME , P#} находится в 3НФ, но присутствует избыточность, S# | SNAME | P# | QTY | ----------------------- S1 | smith | P1 | 200 | S1 | smith | P2 | 300 | S1 | smith | P3 | 400 | S1 | smith | P4 | 500 | если надо обновить имя Smith то придется найти все вхождения, или же база придет в противоречивое состояние, когда в одной строке будет S1 = Smith, а в другой S1 != Smith лучше разбить SP на 2 проекции SS {S#, SNAME } SP {S#, P#, QTY } или SS {S#, SNAME } SP { SNAME , P#, QTY } Не все нужно декомпозировать. Если получаются в результате отношения в НФБК , но они становятся зависимыми, не стоит этого делать, можно считать настоящую форму атомарной. Итак, после всего можно привести определение 3НФ (без ограничения) и НФБК Предположим что есть переменная отношения R , что Х является некоторым подмножество атрибутов этой переменной отношения R и что А является некоторым отдельным атрибутом переменной отношения R. Переменная отношения R находится в 3НФ тогда и только тогда, когда для каждой функциональной зависимости X -> A в переменной отношения R верно по крайней мере одно из следующих высказываний: Подмножество Х включает атрибут А (т.е функц связ тривиальна) Подмножество Х является суперключом переменной отношения R1 Атрибут А входит в состав некоторого потенциального ключа переменной отношения R. Если исключить 3 утверждение получится НФБК, которая является более строгим ограничением по сравнению с 3НФ, и является причиной ввода НФБК. Вернемся к нашему примеру. К данному моменту мы имеем уже 8 следующиx таблиц: haircolors=# \\dt List of relations Schema | Name | Type | Owner --------+---------------+-------+---------- public | address | table | postgres public | manufacturer | table | postgres public | order_details | table | postgres public | orders | table | postgres public | partner | table | postgres public | person | table | postgres public | product | table | postgres public | salon | table | postgres (8 rows) haircolors = # \\d address Table \"public.address\" Column | Type | Modifiers ----------+------------------------+----------- id | integer | not null city | character varying ( 128 ) | not null building | integer | not null flat_no | integer | not null street | character varying ( 128 ) | not null zip_code | integer | not null Indexes : \"address_pkey\" PRIMARY KEY , btree ( id ) Referenced by : TABLE \"person\" CONSTRAINT \"fk_address_id\" FOREIGN KEY ( address_id ) REFERENCES address ( id ) haircolors = # \\d manufacturer Table \"public.manufacturer\" Column | Type | Modifiers -----------------+------------------------+----------- manufacturer_id | integer | not null name | character varying ( 256 ) | not null Indexes : \"manufacturer_pkey\" PRIMARY KEY , btree ( manufacturer_id ) Referenced by : TABLE \"product\" CONSTRAINT \"product_manufacturer_id_fkey\" FOREIGN KEY ( manufacturer_id ) REFERENCES manufacturer ( manufacturer_id ) haircolors = # \\d order_details Table \"public.order_details\" Column | Type | Modifiers ------------------+-----------------------------+-------------------------------------------------------------------------- order_details_id | integer | not null default nextval (' order_details_order_details_id_seq ' :: regclass ) dateorder | timestamp without time zone | qty | integer | Indexes: \"order_details_pkey\" PRIMARY KEY , btree ( order_details_id ) Referenced by: TABLE \"orders\" CONSTRAINT \"orders_order_details_id_fkey\" FOREIGN KEY ( order_details_id ) REFERENCES order_details ( order_details_id ) haircolors = # \\d orders Table \"public.orders\" Column | Type | Modifiers ------------------+---------+----------- id | integer | not null product_id | integer | partner_id | integer | order_details_id | integer | Indexes : \"orders_pkey\" PRIMARY KEY , btree ( id ) Foreign - key constraints : \"orders_order_details_id_fkey\" FOREIGN KEY ( order_details_id ) REFERENCES order_details ( order_details_id ) \"orders_partner_id_fkey\" FOREIGN KEY ( partner_id ) REFERENCES partner ( partner_id ) \"orders_product_id_fkey\" FOREIGN KEY ( product_id ) REFERENCES product ( product_id ) haircolors = # \\d partner Table \"public.partner\" Column | Type | Modifiers ------------+---------+-------------------------------------------------------------- partner_id | integer | not null default nextval ( 'partner_partner_id_seq' :: regclass ) person_id | integer | salon_id | integer | Indexes : \"partner_pkey\" PRIMARY KEY , btree ( partner_id ) Foreign - key constraints : \"partner_person_id_fkey\" FOREIGN KEY ( person_id ) REFERENCES person ( person_id ) \"partner_salon_id_fkey\" FOREIGN KEY ( salon_id ) REFERENCES salon ( salon_id ) Referenced by : TABLE \"orders\" CONSTRAINT \"orders_partner_id_fkey\" FOREIGN KEY ( partner_id ) REFERENCES partner ( partner_id ) haircolors = # \\d person Table \"public.person\" Column | Type | Modifiers -------------+------------------------+----------- person_id | integer | not null firstname | character varying ( 128 ) | not null lastname | character varying ( 128 ) | not null phonenumber | character varying ( 20 ) | not null address_id | integer | Indexes : \"person_pkey\" PRIMARY KEY , btree ( person_id ) \"person_address_key\" UNIQUE CONSTRAINT , btree ( address_id ) Foreign - key constraints : \"fk_address_id\" FOREIGN KEY ( address_id ) REFERENCES address ( id ) Referenced by : TABLE \"partner\" CONSTRAINT \"partner_person_id_fkey\" FOREIGN KEY ( person_id ) REFERENCES person ( person_id ) haircolors = # \\d product Table \"public.product\" Column | Type | Modifiers -----------------+------------------------+----------- product_id | integer | not null name | character varying ( 256 ) | manufacturer_id | integer | price | money | Indexes : \"product_pkey\" PRIMARY KEY , btree ( product_id ) Foreign - key constraints : \"product_manufacturer_id_fkey\" FOREIGN KEY ( manufacturer_id ) REFERENCES manufacturer ( manufacturer_id ) Referenced by : TABLE \"orders\" CONSTRAINT \"orders_product_id_fkey\" FOREIGN KEY ( product_id ) REFERENCES product ( product_id ) haircolors = # \\d salon Table \"public.salon\" Column | Type | Modifiers ------------+------------------------+---------------------------------------------------------- salon_id | integer | not null default nextval ( 'salon_salon_id_seq' :: regclass ) salon_name | character varying ( 128 ) | not null Indexes : \"salon_pkey\" PRIMARY KEY , btree ( salon_id ) Referenced by : TABLE \"partner\" CONSTRAINT \"partner_salon_id_fkey\" FOREIGN KEY ( salon_id ) REFERENCES salon ( salon_id ) haircolors=# select * from address ; id | city | building | flat_no | street | zip_code ----+-------------+----------+---------+-------------------------+---------- 1 | Севастополь | 77 | 54 | ул. Александра Косарева | 299006 2 | Севастополь | 1 | 55 | ул. Кесаева | 299003 (2 rows) Обратим внимание на таблицу ADDRESS , явно не находится во 2НФ, у нас присутствуют дубликаты города, если будет большая таблица, и нужно будет изменить значение города, то можно ошибиться и какая то запись станет не актуальной. Поэтому вынесем город в отдельную таблицу. CREATE TABLE CITY ( CITY_ID SERIAL PRIMARY KEY , CITY_NAME VARCHAR ( 128 ) ); INSERT INTO CITY ( CITY_NAME ) VALUES ( 'Севастополь' ); haircolors=# select * from city; city_id | city_name ---------+------------- 1 | Севастополь (1 row) Добавим столбец address.city_id как внешний ключ ссылку на city.city_id. Обновим записи таблицы ADDRESS и удалим затем столбец CITY . ALTER TABLE address ADD COLUMN city_id INT REFERENCES city ( city_id ); UPDATE address SET city_id = 1 ; ALTER TABLE address DROP COLUMN city ; haircolors = # \\d address Table \"public.address\" Column | Type | Modifiers ----------+------------------------+----------- id | integer | not null building | integer | not null flat_no | integer | not null street | character varying ( 128 ) | not null zip_code | integer | not null city_id | integer | Indexes : \"address_pkey\" PRIMARY KEY , btree ( id ) Foreign - key constraints : \"address_city_id_fkey\" FOREIGN KEY ( city_id ) REFERENCES city ( city_id ) Referenced by : TABLE \"person\" CONSTRAINT \"fk_address_id\" FOREIGN KEY ( address_id ) REFERENCES address ( id ) haircolors=# select * from address ; id | building | flat_no | street | zip_code | city_id ----+----------+---------+-------------------------+----------+--------- 1 | 77 | 54 | ул. Александра Косарева | 299006 | 1 2 | 1 | 55 | ул. Кесаева | 299003 | 1 (2 rows) Все, дубликатов нет, таблица соответствует 2НФ, можно вспомнить, что в реальном мире существует связь - одному почтовому индексу соответствует четкий перечень некоторых улиц, следовательно у нас существует транзитивная связь между столбцами street и zip_code, а именно - мы можем вычислить zip_code по street, типа того как мы бы открыли справочник, нашли свою улицу и соответствующий ей индекс. Это я думаю наглядный пример приведения к 3НФ, мы нашли транзитивную связь и пытаемся избавиться от нее (поправьте если я неправ). Создадим таблицу почтовых индексов и справочник почтовых индексов: CREATE TABLE ZIP_CODE ( ZIP_CODE INT PRIMARY KEY ); INSERT INTO ZIP_CODE ( ZIP_CODE ) VALUES ( 299006 ); INSERT INTO ZIP_CODE ( ZIP_CODE ) VALUES ( 299003 ); haircolors=# select * from zip_code; zip_code ---------- 299006 299003 (2 rows) Положительный момент, теперь мы имеем список индексов и можем добавить новый индекс без проблем, ранее же мы могли указать индекс только в составе существующего адреса. Плюс мы контролируем целостность, т.е. мы не сможем добавить 2 одинаковых почтовых индекса в таблицу. haircolors=# \\d zip_code Table \"public.zip_code\" Column | Type | Modifiers ----------+---------+----------- zip_code | integer | not null Indexes: \"zip_code_pkey\" PRIMARY KEY, btree (zip_code) Referenced by: TABLE \"zip_code_catalog\" CONSTRAINT \"zip_code_catalog_zip_code_fkey\" FOREIGN KEY (zip_code) REFERENCES zip_code(zip_code) Предположим что не бывает 2 одинаковых улицы в городе, тогда значение название улицы уникально: CREATE TABLE ZIP_CODE_CATALOG ( STREET VARCHAR ( 128 ) PRIMARY KEY , ZIP_CODE INT REFERENCES ZIP_CODE ( ZIP_CODE ) ); INSERT INTO ZIP_CODE_CATALOG ( STREET , ZIP_CODE ) VALUES ( 'ул. Александра Косарева' , 299006 ); INSERT INTO ZIP_CODE_CATALOG ( STREET , ZIP_CODE ) VALUES ( 'ул. Кесаева' , 299003 ); haircolors=# select * from zip_code_catalog ; street | zip_code -------------------------+---------- ул. Александра Косарева | 299006 ул. Кесаева | 299003 (2 rows) haircolors = # \\d zip_code_catalog Table \"public.zip_code_catalog\" Column | Type | Modifiers ----------+------------------------+----------- street | character varying ( 128 ) | not null zip_code | integer | Indexes : \"zip_code_catalog_pkey\" PRIMARY KEY , btree ( street ) Foreign - key constraints : \"zip_code_catalog_zip_code_fkey\" FOREIGN KEY ( zip_code ) REFERENCES zip_code ( zip_code ) Теперь поправим таблицу ADDRESS : Удалим столбец zip_code , он нам уже не нужен: ALTER TABLE address DROP COLUMN zip_code ; Добавим ограничение на столбец street пусть он будет внешним ключом ссылающимся на первичный ключ zip_code_catalog.street ALTER TABLE address ADD FOREIGN KEY ( street ) REFERENCES zip_code_catalog ( street ); Выглядит теперь таблица ADDRESS так: haircolors = # \\d address Table \"public.address\" Column | Type | Modifiers ----------+------------------------+----------- id | integer | not null building | integer | not null flat_no | integer | not null street | character varying ( 128 ) | not null city_id | integer | Indexes : \"address_pkey\" PRIMARY KEY , btree ( id ) Foreign - key constraints : \"address_city_id_fkey\" FOREIGN KEY ( city_id ) REFERENCES city ( city_id ) \"address_street_fkey\" FOREIGN KEY ( street ) REFERENCES zip_code_catalog ( street ) Referenced by : TABLE \"person\" CONSTRAINT \"fk_address_id\" FOREIGN KEY ( address_id ) REFERENCES address ( id ) Мы избавились от столбца zip_code и качество управления целостностью данных возросло. Мы теперь можем пополнять список почтовых индексов, где автоматически контролируется уникальность, мы также добились независимости почтового индекса от других данных. Мы создали справочник улиц принадлежащих какому то из почтовых индексов, опять же, контролируем название улицы, мы не сможем добавить 2 одинаковые улицы с какими то индексами в справочник zip_code_catalog (мы условились, что 1 улице можно присвоить 1 уникальный индекс) haircolors=# select * from address ; id | building | flat_no | street | city_id ----+----------+---------+-------------------------+--------- 1 | 77 | 54 | ул. Александра Косарева | 1 2 | 1 | 55 | ул. Кесаева | 1 (2 rows) На этом можно считать пример приведения ADDRESS к 3НФ успешным, мы поступили практически подобно примеру разделив данные. Остальные данные находятся в 3НФ, мы видим насколько мы декомпозировали исходную таблицу, создав некоторое количество таблиц. haircolors=# select * from manufacturer ; manufacturer_id | name -----------------+-------- 1 | Matrix 2 | Loreal 3 | Blond 4 | Союз (4 rows) haircolors=# select * from order_details; order_details_id | dateorder | qty ------------------+---------------------+----- 1 | 2017-07-03 12:15:01 | 3 2 | 2017-07-03 12:16:01 | 2 3 | 2017-07-02 11:01:01 | 12 4 | 2017-07-02 11:01:01 | 120 (4 rows) haircolors=# select * from orders; id | product_id | partner_id | order_details_id ----+------------+------------+------------------ 5 | 1 | 1 | 1 6 | 1 | 2 | 1 7 | 1 | 3 | 1 8 | 2 | 1 | 2 9 | 2 | 2 | 2 10 | 2 | 3 | 2 11 | 3 | 4 | 3 12 | 3 | 5 | 3 13 | 3 | 6 | 3 14 | 4 | 4 | 4 15 | 4 | 5 | 4 16 | 4 | 6 | 4 (12 rows) haircolors=# select * from partner; partner_id | person_id | salon_id ------------+-----------+---------- 1 | 1 | 1 2 | 1 | 2 3 | 1 | 4 4 | 2 | 3 5 | 2 | 4 6 | 2 | 5 (6 rows) haircolors = # select * from person ; person_id | firstname | lastname | phonenumber | address_id -----------+-----------+----------+--------------+------------ 1 | Денис | Петров | + 79784567897 | 1 2 | Юлия | Бабкина | + 79784168585 | 2 ( 2 rows ) haircolors=# select * from product ; product_id | name | manufacturer_id | price ------------+-----------------------+-----------------+------------ 1 | Краска для волос | 1 | 899.01 руб 2 | Краска для волос | 2 | 599.12 руб 3 | Краска для волос | 3 | 299.12 руб 4 | Полотенца одноразовые | 4 | 199.12 руб (4 rows) Tаблицу SALON которая находится в НФБК в дальнейшем можно декомпозировать к 1 столбцу, который и будет являться первичным ключом, маловерятно что может понадобиться иметь 2 одинаковых имен салонов, но я оставляю уникальность по цифровому первичному ключу, так как удобнее работать. Хотя это и некоторая избыточность. haircolors=# select * from salon; salon_id | salon_name ----------+------------ 1 | Е-Студия 2 | Ле-туаль 3 | UpDo 4 | ViVa 5 | Diana (5 rows) Как видно, 3НФ достаточна чтоб избавиться от избыточности, которая может приводить к проблемам обновления, но изза того что данные разъединены теперь немного сложнее представить полную картину, попробуем нарисовать диаграмму нашей базы данных Я попробовал несколько продуктов, например draw.io , но остановился на DBDesigner , мне понравилось, бесплатный, быстро и красиво. Теперь связи стали нагляднее, после визуализации стало намного проще воспринять зависимости (ключик означает первичный ключ PRIMARY KEY , стрелка от значения на диаграмме означает что данный столбец это внешний ключ FOREIGN KEY , ссылающийся на один из первичных ключей). Немного жаль что никак специально не отображается визуально связь ОДИН К ОДНОМУ, например у нас такая связь обозначена между таблицами PERSON и ADDRESS для поля address_id в таблице PERSON мы включили уникальность, и в редакторе тоже это указано, но графически это ничем не отличается от изображения FOREIGN KEY . Напомню как выглядит связь ОДИН К ОДНОМУ : haircolors = # \\d person Table \"public.person\" Column | Type | Modifiers -------------+------------------------+----------- person_id | integer | not null firstname | character varying ( 128 ) | not null lastname | character varying ( 128 ) | not null phonenumber | character varying ( 20 ) | not null address_id | integer | Indexes : \"person_pkey\" PRIMARY KEY , btree ( person_id ) \"person_address_key\" UNIQUE CONSTRAINT , btree ( address_id ) Foreign - key constraints : \"fk_address_id\" FOREIGN KEY ( address_id ) REFERENCES address ( id ) Referenced by : TABLE \"partner\" CONSTRAINT \"partner_person_id_fkey\" FOREIGN KEY ( person_id ) REFERENCES person ( person_id ) как видно мы добавили уникальность внешнему ключу address_id, и теперь адрес из таблицы address может быть назначен только одному уникальному человеку. Два разных человека не смогут иметь один и тот же адрес. haircolors = # \\d address Table \"public.address\" Column | Type | Modifiers ----------+------------------------+----------- id | integer | not null building | integer | not null flat_no | integer | not null street | character varying ( 128 ) | not null city_id | integer | Indexes : \"address_pkey\" PRIMARY KEY , btree ( id ) Foreign - key constraints : \"address_city_id_fkey\" FOREIGN KEY ( city_id ) REFERENCES city ( city_id ) \"address_street_fkey\" FOREIGN KEY ( street ) REFERENCES zip_code_catalog ( street ) Referenced by : TABLE \"person\" CONSTRAINT \"fk_address_id\" FOREIGN KEY ( address_id ) REFERENCES address ( id ) Связь ОДИН КО МНОГИМ В нашем случае связи созданные как внешний ключ ссылающийся на первичный ключ и являются отражением связи ОДИН КО МНОГИМ . Например поле zip_code в zip_code_catalog является внешним ключом ссылающимся на уникальный ключ (первичный ключ) таблицы zip_code. Чем мы собственно хотим указать в таблице zip_code_catalog, что несколько уникальных улиц могут ссылаться на один и тот же индекс. (один и тот же индекс -> много улиц). haircolors=# \\d zip_code Table \"public.zip_code\" Column | Type | Modifiers ----------+---------+----------- zip_code | integer | not null Indexes: \"zip_code_pkey\" PRIMARY KEY, btree (zip_code) Referenced by: TABLE \"zip_code_catalog\" CONSTRAINT \"zip_code_catalog_zip_code_fkey\" FOREIGN KEY (zip_code) REFERENCES zip_code(zip_code) haircolors = # \\d zip_code_catalog Table \"public.zip_code_catalog\" Column | Type | Modifiers ----------+------------------------+----------- street | character varying ( 128 ) | not null zip_code | integer | Indexes : \"zip_code_catalog_pkey\" PRIMARY KEY , btree ( street ) Foreign - key constraints : \"zip_code_catalog_zip_code_fkey\" FOREIGN KEY ( zip_code ) REFERENCES zip_code ( zip_code ) Referenced by : TABLE \"address\" CONSTRAINT \"address_street_fkey\" FOREIGN KEY ( street ) REFERENCES zip_code_catalog ( street ) Связь МНОГИЕ КО МНОГИМ В нашем случае это таблицы PARTNER и ORDERS . В таблице PARTNER мы таким образом выражаем ситуацию что много PERSON могут быть поставщиками SALON , т.е. другими более человечными словами - любой человек может поставлять товары в любой салон. И в этой таблице мы отображаем что человек с PERSON_ID является поставщиком какого то салона с SALON_ID, т.е фактически партнер. Cвязь МНОГИЕ КО МНОГИМ образуется через связующую таблицу, которой является в данном случае partner. haircolors = # \\d partner Table \"public.partner\" Column | Type | Modifiers ------------+---------+-------------------------------------------------------------- partner_id | integer | not null default nextval ( 'partner_partner_id_seq' :: regclass ) person_id | integer | salon_id | integer | Indexes : \"partner_pkey\" PRIMARY KEY , btree ( partner_id ) Foreign - key constraints : \"partner_person_id_fkey\" FOREIGN KEY ( person_id ) REFERENCES person ( person_id ) \"partner_salon_id_fkey\" FOREIGN KEY ( salon_id ) REFERENCES salon ( salon_id ) Referenced by : TABLE \"orders\" CONSTRAINT \"orders_partner_id_fkey\" FOREIGN KEY ( partner_id ) REFERENCES partner ( partner_id ) Выводы Цель нормализации - избавиться от избыточности, и избежать аномалий обновления к которым приводит избыточность. Каждая переменная отношения на некотором уровне нормализации соответствует условиям более низких уровней нормализации. (переход ко 2й форме возможен если отношение приведено к 1й форме) Всегда можно выполнить приведение к НФБК. Процесс нормализации заключается в замене переменной отношения некоторым набором ее проекций, составленных таким образом, чтобы обратное соединение этих проекций позволяло вновь получить исходную переменную отношения. (т.е. это обратимый процесс, декомпозиция выполняется без потери информации) Нужно разбивать на независимы проекции (независимые одна от другой), тогда это будет декомпозиция с сохранением зависимостей. На этом я хочу закончить данную статью. В следующей заметке я добавлю очень краткое описание следующих нормальных форм 4НФ, 5НФ и немного понятий о денормализации, а также алгоритм приведения к НФБК. Я действительно на примерх увидел, как нормализация уменьшает избыточность базы данных и препятствует внесению случайных ошибок. Авторы отмечают, что есть более высокие строгие нормальные формы, но на практике обычно используются только первые три. Возможно они и правы, так как допустим 3НФ требует разьеденить почти все составляющие адреса, но если адрес не меняется часто, то чтоб сформировать полную информацию о полях адреса, нам уже как минимум нужно обратиться к нескольким таблицам, что возможно может послужить причиной проблем быстродействия.","tags":"Blog","url":"https://ruthkraus.github.io/2017/07/db-theory-3nf.html","loc":"https://ruthkraus.github.io/2017/07/db-theory-3nf.html"},{"title":"Процедура нормализации данных и нормальные формы данных (1НФ).","text":"Данная заметка, делается в первую очередь для себя после прочтения монументального труда \"Введение в системы баз данных\" автора К. Дж. Дейт. Труд этот очень обширный и затрагивает множество теоретических и практических аспектов связанных с базами данных, теорией их устройства (большей частью затронуты реляционные базы данных). Чтобы как-то оставить информацию в памяти я решил сделать заметку с некоторыми цитатами касательно понятия нормализации, денормализации и понятий нормальных форм. Процедура нормализации это процедура разбиения логически несвязанной информации на отдельные переменные отношения (таблицы). Цель нормализации - избавиться от избыточности, и избежать аномалий обновления к которым приводит избыточность. Проще говоря, преследуется цель разделить данные так, чтоб они были максимально независимыми друг от друга, тогда не возникает проблем с обновлением/удалением/добавлением новых данных. В качестве небольшого отступления для примера создадим базу в PostgreSQL с которой будем проводить эксперимент дальнейших преобразований: postgres=# CREATE DATABASE haircolors; CREATE DATABASE postgres=# postgres=# \\c haircolors You are now connected to database \"haircolors\" as user \"postgres\". haircolors=# \\dt No relations found. Представим, что мы оптовый продавец всякой всячины для салонов красоты и есть некая база данных покупателей которые делают у нас заказы для каких то салонов красоты, которая может выглядеть допустим примерно так: CREATE TABLE CUSTOMERS ( ID INT PRIMARY KEY NOT NULL , FIRSTNAME VARCHAR ( 128 ) NOT NULL , LASTNAME VARCHAR ( 128 ) NOT NULL , PHONENUMBER VARCHAR ( 20 ) NOT NULL , SALON_NAME VARCHAR ( 256 ) NOT NULL , ADDRESS VARCHAR ( 256 ) NOT NULL , MANUFACTURER VARCHAR ( 256 ) NOT NULL , PRODUCT_NAME VARCHAR ( 256 ) NOT NULL , DATEORDER TIMESTAMP NOT NULL , PRICE MONEY NOT NULL , QTY INT NOT NULL ); Покупатель с FIRSTNAME , LASTNAME , PHONENUMBER который живет по ADDRESS и производит закупки продукции PRODUCT_NAME неких производителей MANUFACTURER по цене PRICE в количестве QTY для салонов SALON_NAME, мы отмечаем дату и время когда произошел заказ DATEORDER . Данный пример больше учебный, взял очень произвольно, попробуем найти проблемы в процессе нормализации. haircolors = # \\d customers Table \"public.customers\" Column | Type | Modifiers --------------+-----------------------------+----------- id | integer | not null firstname | character varying ( 128 ) | not null lastname | character varying ( 128 ) | not null phonenumber | character varying ( 20 ) | not null salon_name | character varying ( 256 ) | not null address | character varying ( 256 ) | not null manufacturer | character varying ( 256 ) | not null product_name | character varying ( 256 ) | not null dateorder | timestamp without time zone | not null price | money | not null qty | integer | not null Indexes : \"customers_pkey\" PRIMARY KEY , btree ( id ) Заполним нашу условную базу данных некоторыми значениями: INSERT INTO CUSTOMERS ( ID , FIRSTNAME , LASTNAME , PHONENUMBER , SALON_NAME , ADDRESS , MANUFACTURER , PRODUCT_NAME , DATEORDER , PRICE , QTY ) VALUES ( 1 , 'Денис' , 'Петров' , '+79784567897' , 'Е-Студия, ViVa, Ле-туаль' , 'ул. Александра Косарева, д.77, кв. 54, Севастополь 299006' , 'Matrix' , 'Краска для волос' , '2017-07-03 12:15:01 +0000' , 899.01 , 3 ); INSERT INTO CUSTOMERS ( ID , FIRSTNAME , LASTNAME , PHONENUMBER , SALON_NAME , ADDRESS , MANUFACTURER , PRODUCT_NAME , DATEORDER , PRICE , QTY ) VALUES ( 2 , 'Денис' , 'Петров' , '+79784567897' , 'Е-Студия, ViVa, Ле-туаль' , 'ул. Александра Косарева, д.77, кв. 54, Севастополь 299006' , 'Loreal' , 'Краска для волос' , '2017-07-03 12:16:01 +0000' , 599.12 , 2 ); INSERT INTO CUSTOMERS ( ID , FIRSTNAME , LASTNAME , PHONENUMBER , SALON_NAME , ADDRESS , MANUFACTURER , PRODUCT_NAME , DATEORDER , PRICE , QTY ) VALUES ( 3 , 'Юлия' , 'Бабкина' , '+79784168585' , 'UpDo, ViVa, Diana' , 'ул. Кесаева, д.1, кв. 55, Севастополь 299003' , 'Blond' , 'Краска для волос' , '2017-07-02 11:01:01 +0000' , 299.12 , 12 ); INSERT INTO CUSTOMERS ( ID , FIRSTNAME , LASTNAME , PHONENUMBER , SALON_NAME , ADDRESS , MANUFACTURER , PRODUCT_NAME , DATEORDER , PRICE , QTY ) VALUES ( 4 , 'Юлия' , 'Бабкина' , '+79784168585' , 'UpDo, ViVa, Diana' , 'ул. Кесаева, д.1, кв. 55, Севастополь 299003' , 'Союз' , 'Полотенца одноразовые' , '2017-07-02 11:01:01 +0000' , 199.12 , 120 ); Из произвольно набранных данных видим, что таблица не удовлетворяет 1НФ: Первая нормальная форма 1НФ - переменная отношения находится в 1нф тогда и только тогда, когда в любом допустимом значении этой переменной отношения (таблицы) каждый ее кортеж содержит одно значение для каждого из атрибутов (столбцов). (короче говоря, повторяющиеся группы п1,п2,п3 в значении столбца запрещены) (фактически избавляемся от дубликации информации в ячейке столбца - не должно быть столбцов которые в ячейке имеют данные через запятую) haircolors = # select * from customers ; id | firstname | lastname | phonenumber | salon_name | address | manufacturer | product_name | dateorder | price | qty ----+-----------+----------+--------------+--------------------------+-----------------------------------------------------------+--------------+-----------------------+---------------------+------------+----- 1 | Денис | Петров | + 79784567897 | Е - Студия , ViVa , Ле - туаль | ул . Александра Косарева , д . 77 , кв . 54 , Севастополь 299006 | Matrix | Краска для волос | 2017 - 07 - 03 12 : 15 : 01 | 899.01 руб | 3 2 | Денис | Петров | + 79784567897 | Е - Студия , ViVa , Ле - туаль | ул . Александра Косарева , д . 77 , кв . 54 , Севастополь 299006 | Loreal | Краска для волос | 2017 - 07 - 03 12 : 15 : 01 | 599.12 руб | 2 3 | Юлия | Бабкина | + 79784168585 | UpDo , ViVa , Diana | ул . Кесаева , д . 1 , кв . 55 , Севастополь 299003 | Blond | Краска для волос | 2017 - 07 - 02 11 : 01 : 01 | 299.12 руб | 12 4 | Юлия | Бабкина | + 79784168585 | UpDo , ViVa , Diana | ул . Кесаева , д . 1 , кв . 55 , Севастополь 299003 | Союз | Полотенца одноразовые | 2017 - 07 - 02 11 : 01 : 01 | 199.12 руб | 120 ( 4 rows ) Здесь явно что то не так как минимум со столбцом salon_name в котором имеются данные по смыслу означающие разные салоны (разные сущности) перечисленные через запятую. Например если я захочу добавить заказчику \"Денис Петров\" еще 1 название салона, мне придется обновить все записи, причем не забыть ни одного вхождения. В примере малое количество записей (строк) и поэтому кажется ничего страшного, но представим что записей сотни тысяч и проблема станет ощутимее. Кроме того очень неудобно работать с данными которые представлены вот так через запятую. Для получения какой либо полезной информации придется как то парсить значение этого столбца. Можно также увидеть что покупатель Юлия Бабкина поставляет товары в тот же салон ViVa, что и Денис Петров, следовательно сделаем заключение, что \"несколько разных покупателей могут поставлять продукцию в один и тот же салон. Приведем данные к первой нормальной форме, для чего создадим таблицу SALON c полями (столбцами) SALON_ID# и SALON_NAME, (на самом-то деле сейчас нет особой надобности в поле SALON_ID#, так как само имя салона может являться первичным ключом, но представим, вдруг у нас могут быть 2 салона с одинаковым именем, и нам все же придется их как то различать) - вынесем возможные значения salon_name и привяжем с помощью внешнего ключа к нашей таблице customers . CREATE TABLE SALON ( SALON_ID SERIAL PRIMARY KEY , SALON_NAME VARCHAR ( 128 ) NOT NULL ); haircolors = # \\d salon Table \"public.salon\" Column | Type | Modifiers ------------+------------------------+---------------------------------------------------------- salon_id | integer | not null default nextval ( 'salon_salon_id_seq' :: regclass ) salon_name | character varying ( 128 ) | not null Indexes : \"salon_pkey\" PRIMARY KEY , btree ( salon_id ) Добавим значения - названия салонов в таблицу SALON : INSERT INTO salon ( salon_name ) VALUES ( 'Е-Студия' ); INSERT INTO salon ( salon_name ) VALUES ( 'Ле-туаль' ); INSERT INTO salon ( salon_name ) VALUES ( 'UpDo' ); INSERT INTO salon ( salon_name ) VALUES ( 'ViVa' ); INSERT INTO salon ( salon_name ) VALUES ( 'Diana' ); получается следующее, обратим внимание что salon_id заполнен автоматически, мы не определяли его значение: haircolors=# select * from salon; salon_id | salon_name ----------+------------ 1 | Е-Студия 2 | Ле-туаль 3 | UpDo 4 | ViVa 5 | Diana (5 rows) Переименуем столбец таблицы CUSTOMERS salon_name в salon_name_old ALTER TABLE CUSTOMERS RENAME COLUMN SALON_NAME TO SALON_NAME_OLD ; Добавим столбец salon_name как внешний ключ который ссылается на первичный ключ таблицы SALON salon_id . Cначала создадим столбец, потом \"навесим\" на него ограничение: ALTER TABLE customers ADD COLUMN SALON_NAME INT ; ALTER TABLE customers ADD CONSTRAINT fk_salon_name FOREIGN KEY ( salon_name ) REFERENCES salon ( salon_id ); Ради примера удалим допустим ограничение NOT NULL столбца salon_name_old : ALTER TABLE customers ALTER COLUMN salon_name_old DROP NOT NULL ; Можем наблюдать нами созданный столбец и ограничение: haircolors = # \\d customers Table \"public.customers\" Column | Type | Modifiers ----------------+-----------------------------+----------- id | integer | not null firstname | character varying ( 128 ) | not null lastname | character varying ( 128 ) | not null phonenumber | character varying ( 20 ) | not null salon_name_old | character varying ( 256 ) | address | character varying ( 256 ) | not null manufacturer | character varying ( 256 ) | not null product_name | character varying ( 256 ) | not null dateorder | timestamp without time zone | not null price | money | not null qty | integer | not null salon_name | integer | Indexes : \"customers_pkey\" PRIMARY KEY , btree ( id ) Foreign - key constraints : \"fk_salon_name\" FOREIGN KEY ( salon_name ) REFERENCES salon ( salon_id ) Теперь пришла очередь заполнить колонку salon_name таблицы CUSTOMERS : INSERT INTO CUSTOMERS ( ID , FIRSTNAME , LASTNAME , PHONENUMBER , SALON_NAME_OLD , ADDRESS , MANUFACTURER , PRODUCT_NAME , DATEORDER , PRICE , QTY , SALON_NAME ) VALUES ( 5 , 'Денис' , 'Петров' , '+79784567897' , 'Е-Студия, ViVa, Ле-туаль' , 'ул. Александра Косарева, д.77, кв. 54, Севастополь 299006' , 'Matrix' , 'Краска для волос' , '2017-07-03 12:15:01 +0000' , 899.01 , 3 , 1 ); INSERT INTO CUSTOMERS ( ID , FIRSTNAME , LASTNAME , PHONENUMBER , SALON_NAME_OLD , ADDRESS , MANUFACTURER , PRODUCT_NAME , DATEORDER , PRICE , QTY , SALON_NAME ) VALUES ( 6 , 'Денис' , 'Петров' , '+79784567897' , 'Е-Студия, ViVa, Ле-туаль' , 'ул. Александра Косарева, д.77, кв. 54, Севастополь 299006' , 'Matrix' , 'Краска для волос' , '2017-07-03 12:15:01 +0000' , 899.01 , 3 , 2 ); INSERT INTO CUSTOMERS ( ID , FIRSTNAME , LASTNAME , PHONENUMBER , SALON_NAME_OLD , ADDRESS , MANUFACTURER , PRODUCT_NAME , DATEORDER , PRICE , QTY , SALON_NAME ) VALUES ( 7 , 'Денис' , 'Петров' , '+79784567897' , 'Е-Студия, ViVa, Ле-туаль' , 'ул. Александра Косарева, д.77, кв. 54, Севастополь 299006' , 'Matrix' , 'Краска для волос' , '2017-07-03 12:15:01 +0000' , 899.01 , 3 , 4 ); INSERT INTO CUSTOMERS ( ID , FIRSTNAME , LASTNAME , PHONENUMBER , SALON_NAME_OLD , ADDRESS , MANUFACTURER , PRODUCT_NAME , DATEORDER , PRICE , QTY , SALON_NAME ) VALUES ( 8 , 'Денис' , 'Петров' , '+79784567897' , 'Е-Студия, ViVa, Ле-туаль' , 'ул. Александра Косарева, д.77, кв. 54, Севастополь 299006' , 'Loreal' , 'Краска для волос' , '2017-07-03 12:16:01 +0000' , 599.12 , 2 , 1 ); INSERT INTO CUSTOMERS ( ID , FIRSTNAME , LASTNAME , PHONENUMBER , SALON_NAME_OLD , ADDRESS , MANUFACTURER , PRODUCT_NAME , DATEORDER , PRICE , QTY , SALON_NAME ) VALUES ( 9 , 'Денис' , 'Петров' , '+79784567897' , 'Е-Студия, ViVa, Ле-туаль' , 'ул. Александра Косарева, д.77, кв. 54, Севастополь 299006' , 'Loreal' , 'Краска для волос' , '2017-07-03 12:16:01 +0000' , 599.12 , 2 , 2 ); INSERT INTO CUSTOMERS ( ID , FIRSTNAME , LASTNAME , PHONENUMBER , SALON_NAME_OLD , ADDRESS , MANUFACTURER , PRODUCT_NAME , DATEORDER , PRICE , QTY , SALON_NAME ) VALUES ( 10 , 'Денис' , 'Петров' , '+79784567897' , 'Е-Студия, ViVa, Ле-туаль' , 'ул. Александра Косарева, д.77, кв. 54, Севастополь 299006' , 'Loreal' , 'Краска для волос' , '2017-07-03 12:16:01 +0000' , 599.12 , 2 , 4 ); INSERT INTO CUSTOMERS ( ID , FIRSTNAME , LASTNAME , PHONENUMBER , SALON_NAME_OLD , ADDRESS , MANUFACTURER , PRODUCT_NAME , DATEORDER , PRICE , QTY , SALON_NAME ) VALUES ( 11 , 'Юлия' , 'Бабкина' , '+79784168585' , 'UpDo, ViVa, Diana' , 'ул. Кесаева, д.1, кв. 55, Севастополь 299003' , 'Blond' , 'Краска для волос' , '2017-07-02 11:01:01 +0000' , 299.12 , 12 , 3 ); INSERT INTO CUSTOMERS ( ID , FIRSTNAME , LASTNAME , PHONENUMBER , SALON_NAME_OLD , ADDRESS , MANUFACTURER , PRODUCT_NAME , DATEORDER , PRICE , QTY , SALON_NAME ) VALUES ( 12 , 'Юлия' , 'Бабкина' , '+79784168585' , 'UpDo, ViVa, Diana' , 'ул. Кесаева, д.1, кв. 55, Севастополь 299003' , 'Blond' , 'Краска для волос' , '2017-07-02 11:01:01 +0000' , 299.12 , 12 , 4 ); INSERT INTO CUSTOMERS ( ID , FIRSTNAME , LASTNAME , PHONENUMBER , SALON_NAME_OLD , ADDRESS , MANUFACTURER , PRODUCT_NAME , DATEORDER , PRICE , QTY , SALON_NAME ) VALUES ( 13 , 'Юлия' , 'Бабкина' , '+79784168585' , 'UpDo, ViVa, Diana' , 'ул. Кесаева, д.1, кв. 55, Севастополь 299003' , 'Blond' , 'Краска для волос' , '2017-07-02 11:01:01 +0000' , 299.12 , 12 , 5 ); INSERT INTO CUSTOMERS ( ID , FIRSTNAME , LASTNAME , PHONENUMBER , SALON_NAME_OLD , ADDRESS , MANUFACTURER , PRODUCT_NAME , DATEORDER , PRICE , QTY , SALON_NAME ) VALUES ( 14 , 'Юлия' , 'Бабкина' , '+79784168585' , 'UpDo, ViVa, Diana' , 'ул. Кесаева, д.1, кв. 55, Севастополь 299003' , 'Союз' , 'Полотенца одноразовые' , '2017-07-02 11:01:01 +0000' , 199.12 , 120 , 3 ); INSERT INTO CUSTOMERS ( ID , FIRSTNAME , LASTNAME , PHONENUMBER , SALON_NAME_OLD , ADDRESS , MANUFACTURER , PRODUCT_NAME , DATEORDER , PRICE , QTY , SALON_NAME ) VALUES ( 15 , 'Юлия' , 'Бабкина' , '+79784168585' , 'UpDo, ViVa, Diana' , 'ул. Кесаева, д.1, кв. 55, Севастополь 299003' , 'Союз' , 'Полотенца одноразовые' , '2017-07-02 11:01:01 +0000' , 199.12 , 120 , 4 ); INSERT INTO CUSTOMERS ( ID , FIRSTNAME , LASTNAME , PHONENUMBER , SALON_NAME_OLD , ADDRESS , MANUFACTURER , PRODUCT_NAME , DATEORDER , PRICE , QTY , SALON_NAME ) VALUES ( 16 , 'Юлия' , 'Бабкина' , '+79784168585' , 'UpDo, ViVa, Diana' , 'ул. Кесаева, д.1, кв. 55, Севастополь 299003' , 'Союз' , 'Полотенца одноразовые' , '2017-07-02 11:01:01 +0000' , 199.12 , 120 , 5 ); База значительно выросла, но не страшно, зато мы убрали перечисление в столбце: haircolors = # select * from customers; id | firstname | lastname | phonenumber | salon_name_old | address | manufacturer | product_name | dateorder | price | qty | salon_name ----+-----------+----------+--------------+--------------------------+-----------------------------------------------------------+--------------+-----------------------+---------------------+------------+-----+------------ 1 | Денис | Петров | + 79784567897 | Е - Студия , ViVa , Ле - туаль | ул . Александра Косарева , д . 77 , кв . 54 , Севастополь 299006 | Matrix | Краска для волос | 2017 - 07 - 03 12 : 15 : 01 | 899.01 руб | 3 | 2 | Денис | Петров | + 79784567897 | Е - Студия , ViVa , Ле - туаль | ул . Александра Косарева , д . 77 , кв . 54 , Севастополь 299006 | Loreal | Краска для волос | 2017 - 07 - 03 12 : 15 : 01 | 599.12 руб | 2 | 3 | Юлия | Бабкина | + 79784168585 | UpDo , ViVa , Diana | ул . Кесаева , д . 1 , кв . 55 , Севастополь 299003 | Blond | Краска для волос | 2017 - 07 - 02 11 : 01 : 01 | 299.12 руб | 12 | 4 | Юлия | Бабкина | + 79784168585 | UpDo , ViVa , Diana | ул . Кесаева , д . 1 , кв . 55 , Севастополь 299003 | Союз | Полотенца одноразовые | 2017 - 07 - 02 11 : 01 : 01 | 199.12 руб | 120 | 5 | Денис | Петров | + 79784567897 | Е - Студия , ViVa , Ле - туаль | ул . Александра Косарева , д . 77 , кв . 54 , Севастополь 299006 | Matrix | Краска для волос | 2017 - 07 - 03 12 : 15 : 01 | 899.01 руб | 3 | 1 6 | Денис | Петров | + 79784567897 | Е - Студия , ViVa , Ле - туаль | ул . Александра Косарева , д . 77 , кв . 54 , Севастополь 299006 | Matrix | Краска для волос | 2017 - 07 - 03 12 : 15 : 01 | 899.01 руб | 3 | 2 7 | Денис | Петров | + 79784567897 | Е - Студия , ViVa , Ле - туаль | ул . Александра Косарева , д . 77 , кв . 54 , Севастополь 299006 | Matrix | Краска для волос | 2017 - 07 - 03 12 : 15 : 01 | 899.01 руб | 3 | 4 8 | Денис | Петров | + 79784567897 | Е - Студия , ViVa , Ле - туаль | ул . Александра Косарева , д . 77 , кв . 54 , Севастополь 299006 | Loreal | Краска для волос | 2017 - 07 - 03 12 : 16 : 01 | 599.12 руб | 2 | 1 9 | Денис | Петров | + 79784567897 | Е - Студия , ViVa , Ле - туаль | ул . Александра Косарева , д . 77 , кв . 54 , Севастополь 299006 | Loreal | Краска для волос | 2017 - 07 - 03 12 : 16 : 01 | 599.12 руб | 2 | 2 10 | Денис | Петров | + 79784567897 | Е - Студия , ViVa , Ле - туаль | ул . Александра Косарева , д . 77 , кв . 54 , Севастополь 299006 | Loreal | Краска для волос | 2017 - 07 - 03 12 : 16 : 01 | 599.12 руб | 2 | 4 11 | Юлия | Бабкина | + 79784168585 | UpDo , ViVa , Diana | ул . Кесаева , д . 1 , кв . 55 , Севастополь 299003 | Blond | Краска для волос | 2017 - 07 - 02 11 : 01 : 01 | 299.12 руб | 12 | 3 12 | Юлия | Бабкина | + 79784168585 | UpDo , ViVa , Diana | ул . Кесаева , д . 1 , кв . 55 , Севастополь 299003 | Blond | Краска для волос | 2017 - 07 - 02 11 : 01 : 01 | 299.12 руб | 12 | 4 13 | Юлия | Бабкина | + 79784168585 | UpDo , ViVa , Diana | ул . Кесаева , д . 1 , кв . 55 , Севастополь 299003 | Blond | Краска для волос | 2017 - 07 - 02 11 : 01 : 01 | 299.12 руб | 12 | 5 14 | Юлия | Бабкина | + 79784168585 | UpDo , ViVa , Diana | ул . Кесаева , д . 1 , кв . 55 , Севастополь 299003 | Союз | Полотенца одноразовые | 2017 - 07 - 02 11 : 01 : 01 | 199.12 руб | 120 | 3 15 | Юлия | Бабкина | + 79784168585 | UpDo , ViVa , Diana | ул . Кесаева , д . 1 , кв . 55 , Севастополь 299003 | Союз | Полотенца одноразовые | 2017 - 07 - 02 11 : 01 : 01 | 199.12 руб | 120 | 4 16 | Юлия | Бабкина | + 79784168585 | UpDo , ViVa , Diana | ул . Кесаева , д . 1 , кв . 55 , Севастополь 299003 | Союз | Полотенца одноразовые | 2017 - 07 - 02 11 : 01 : 01 | 199.12 руб | 120 | 5 ( 16 rows ) Теперь можно удалить столбец salon_name_old и строки с id 1-4, информация о названии салона у нас представлена в столбце salon_name ALTER TABLE customers DROP COLUMN salon_name_old ; DELETE FROM customers WHERE id IN ( 1 , 2 , 3 , 4 ); haircolors = # select * from customers; id | firstname | lastname | phonenumber | address | manufacturer | product_name | dateorder | price | qty | salon_name ----+-----------+----------+--------------+-----------------------------------------------------------+--------------+-----------------------+---------------------+------------+-----+------------ 5 | Денис | Петров | + 79784567897 | ул . Александра Косарева , д . 77 , кв . 54 , Севастополь 299006 | Matrix | Краска для волос | 2017 - 07 - 03 12 : 15 : 01 | 899.01 руб | 3 | 1 6 | Денис | Петров | + 79784567897 | ул . Александра Косарева , д . 77 , кв . 54 , Севастополь 299006 | Matrix | Краска для волос | 2017 - 07 - 03 12 : 15 : 01 | 899.01 руб | 3 | 2 7 | Денис | Петров | + 79784567897 | ул . Александра Косарева , д . 77 , кв . 54 , Севастополь 299006 | Matrix | Краска для волос | 2017 - 07 - 03 12 : 15 : 01 | 899.01 руб | 3 | 4 8 | Денис | Петров | + 79784567897 | ул . Александра Косарева , д . 77 , кв . 54 , Севастополь 299006 | Loreal | Краска для волос | 2017 - 07 - 03 12 : 16 : 01 | 599.12 руб | 2 | 1 9 | Денис | Петров | + 79784567897 | ул . Александра Косарева , д . 77 , кв . 54 , Севастополь 299006 | Loreal | Краска для волос | 2017 - 07 - 03 12 : 16 : 01 | 599.12 руб | 2 | 2 10 | Денис | Петров | + 79784567897 | ул . Александра Косарева , д . 77 , кв . 54 , Севастополь 299006 | Loreal | Краска для волос | 2017 - 07 - 03 12 : 16 : 01 | 599.12 руб | 2 | 4 11 | Юлия | Бабкина | + 79784168585 | ул . Кесаева , д . 1 , кв . 55 , Севастополь 299003 | Blond | Краска для волос | 2017 - 07 - 02 11 : 01 : 01 | 299.12 руб | 12 | 3 12 | Юлия | Бабкина | + 79784168585 | ул . Кесаева , д . 1 , кв . 55 , Севастополь 299003 | Blond | Краска для волос | 2017 - 07 - 02 11 : 01 : 01 | 299.12 руб | 12 | 4 13 | Юлия | Бабкина | + 79784168585 | ул . Кесаева , д . 1 , кв . 55 , Севастополь 299003 | Blond | Краска для волос | 2017 - 07 - 02 11 : 01 : 01 | 299.12 руб | 12 | 5 14 | Юлия | Бабкина | + 79784168585 | ул . Кесаева , д . 1 , кв . 55 , Севастополь 299003 | Союз | Полотенца одноразовые | 2017 - 07 - 02 11 : 01 : 01 | 199.12 руб | 120 | 3 15 | Юлия | Бабкина | + 79784168585 | ул . Кесаева , д . 1 , кв . 55 , Севастополь 299003 | Союз | Полотенца одноразовые | 2017 - 07 - 02 11 : 01 : 01 | 199.12 руб | 120 | 4 16 | Юлия | Бабкина | + 79784168585 | ул . Кесаева , д . 1 , кв . 55 , Севастополь 299003 | Союз | Полотенца одноразовые | 2017 - 07 - 02 11 : 01 : 01 | 199.12 руб | 120 | 5 ( 12 rows ) Вот что получилось, убрали перечисление для названия салонов, но не будем закрывать глаза на перечисление в столбце address , создадим отдельную табличку ADDRESS и заполним данными: CREATE TABLE ADDRESS ( ID INT PRIMARY KEY , CITY VARCHAR ( 128 ) NOT NULL , BUILDING INT NOT NULL , FLAT_NO INT NOT NULL , STREET VARCHAR ( 128 ) NOT NULL , ZIP_CODE INT NOT NULL ); INSERT INTO address ( ID , CITY , STREET , BUILDING , FLAT_NO , ZIP_CODE ) VALUES ( 1 , 'Севастополь' , 'ул. Александра Косарева' , 77 , 54 , 299006 ); INSERT INTO address ( ID , CITY , STREET , BUILDING , FLAT_NO , ZIP_CODE ) VALUES ( 2 , 'Севастополь' , 'ул. Кесаева' , 1 , 55 , 299003 ); haircolors=# select * from address; id | city | building | flat_no | street | zip_code ----+-------------+----------+---------+-------------------------+---------- 1 | Севастополь | 77 | 54 | ул. Александра Косарева | 299006 2 | Севастополь | 1 | 55 | ул. Кесаева | 299003 (2 rows) Теперь переименуем столбец address в таблице CUSTOMERS в address_old , создадим столбец address и заполним соответствующими значениями (пока не будем использовать никакие ограничения) ALTER TABLE CUSTOMERS RENAME COLUMN address TO address_old ; ALTER TABLE CUSTOMERS ADD COLUMN address INT ; UPDATE customers SET address = 1 WHERE id in ( 5 , 6 , 7 , 8 , 9 , 10 ); UPDATE customers SET address = 2 WHERE id not in ( 5 , 6 , 7 , 8 , 9 , 10 ); Проверим, что не потеряли информацию о адресе и удалим столбец address_old ALTER TABLE customers DROP COLUMN address_old ; В результате получится так: haircolors = # ALTER TABLE customers DROP COLUMN address_old ; ALTER TABLE haircolors = # select * from customers ; id | firstname | lastname | phonenumber | manufacturer | product_name | dateorder | price | qty | salon_name | address ----+-----------+----------+--------------+--------------+-----------------------+---------------------+------------+-----+------------+--------- 5 | Денис | Петров | + 79784567897 | Matrix | Краска для волос | 2017 - 07 - 03 12 : 15 : 01 | 899.01 руб | 3 | 1 | 1 6 | Денис | Петров | + 79784567897 | Matrix | Краска для волос | 2017 - 07 - 03 12 : 15 : 01 | 899.01 руб | 3 | 2 | 1 7 | Денис | Петров | + 79784567897 | Matrix | Краска для волос | 2017 - 07 - 03 12 : 15 : 01 | 899.01 руб | 3 | 4 | 1 8 | Денис | Петров | + 79784567897 | Loreal | Краска для волос | 2017 - 07 - 03 12 : 16 : 01 | 599.12 руб | 2 | 1 | 1 9 | Денис | Петров | + 79784567897 | Loreal | Краска для волос | 2017 - 07 - 03 12 : 16 : 01 | 599.12 руб | 2 | 2 | 1 10 | Денис | Петров | + 79784567897 | Loreal | Краска для волос | 2017 - 07 - 03 12 : 16 : 01 | 599.12 руб | 2 | 4 | 1 11 | Юлия | Бабкина | + 79784168585 | Blond | Краска для волос | 2017 - 07 - 02 11 : 01 : 01 | 299.12 руб | 12 | 3 | 2 12 | Юлия | Бабкина | + 79784168585 | Blond | Краска для волос | 2017 - 07 - 02 11 : 01 : 01 | 299.12 руб | 12 | 4 | 2 13 | Юлия | Бабкина | + 79784168585 | Blond | Краска для волос | 2017 - 07 - 02 11 : 01 : 01 | 299.12 руб | 12 | 5 | 2 14 | Юлия | Бабкина | + 79784168585 | Союз | Полотенца одноразовые | 2017 - 07 - 02 11 : 01 : 01 | 199.12 руб | 120 | 3 | 2 15 | Юлия | Бабкина | + 79784168585 | Союз | Полотенца одноразовые | 2017 - 07 - 02 11 : 01 : 01 | 199.12 руб | 120 | 4 | 2 16 | Юлия | Бабкина | + 79784168585 | Союз | Полотенца одноразовые | 2017 - 07 - 02 11 : 01 : 01 | 199.12 руб | 120 | 5 | 2 ( 12 rows ) haircolors = # select * from salon; salon_id | salon_name ----------+------------ 1 | Е - Студия 2 | Ле - туаль 3 | UpDo 4 | ViVa 5 | Diana ( 5 rows ) haircolors = # select * from address ; id | city | building | flat_no | street | zip_code ----+-------------+----------+---------+-------------------------+---------- 1 | Севастополь | 77 | 54 | ул . Александра Косарева | 299006 2 | Севастополь | 1 | 55 | ул . Кесаева | 299003 ( 2 rows ) Итак, мы в конце концов привели нашу первоначальную таблицу к первой нормальной форме 1НФ . Как видим никакие данные в столбцах более не перечисляются. В итоге мы получили 3 разные таблицы которые уже имеют связи, которые несложно проследить такие как: ОДИН КО МНОГИМ salon.salon_id (1) -> customers.salon_name (*), такая связь как видим организована с помощью customers.salon_name ( FOREIGN KEY )(*) -> salon.salon_id ( PRIMARY KEY )(1) ОДИН К ОДНОМУ Мы видим что пара значений firstname, lastname образуют первичный ключ, который может идентифицировать уникального пользователя, который живет по некоторому адресу следовательно прослеживается связь (firstname, lastname) (1) <-> address.id (1). В дальнейшем я вижу возможность использовать это, поэтому решил для упрощения примера не навешивать никаких ограничений, просто опишу эту связь словами. Думаю можно переходить к приведению наших данных ко 2й нормальной форме, о чем будет мой завтрашний рассказ.","tags":"Blog","url":"https://ruthkraus.github.io/2017/07/db-theory-1nf.html","loc":"https://ruthkraus.github.io/2017/07/db-theory-1nf.html"},{"title":"Create Vagrant base box manually from existing one","text":"Vagrant Boxes are prepackaged development environments that are provided by Vagrant. In most cases, this is usually just a stripped and naked operating system such as Ubuntu, Debian, or CentOS. Boxes exist with the intention to be provisioned with additional features like Apache server or PostgreSQL database with Puppet, shell script or anyone of provision tools. The main documentation about Vagrant configuration can be found here This post will describe how to create your own prepackaged Vagrant Box manually from an existing box from https://atlas.hashicorp.com. In my opinion, it's the quickest and easiest way to save time for provisioning default box with Vagrant. We need to provision machine manually once and then use it in the future, of course we can lost flexibility of usual Vagrant approach when I need always run provision process for clean box. This way you'll be able to reuse prepared box over and over and even share it. For example I want to prepare my own box from existing Ubuntu box, many of boxes could be found on https://atlas.hashicorp.com site. I think for my purposes I get hashicorp/precise64 , so I init it: vagrant init hashicorp/precise64 then I need to run it: vagrant up after couple minutes I can enter machine via ssh and start to install things that I think I want to have in my own box: vagrant ssh then do some commands to install mc, postgresql, etc : sudo apt - get update sudo apt - get install - y apache2 sudo apt - get install - y mc sudo apt - get install - y htop sudo apt - get install - y postgresql - 9.1 postgresql - server - dev - 9.1 libpq - dev python - dev python - setuptools sudo apt - get clean All packages that I want already installed, now I can package that instance to my own box: vagrant package --output mynew.box vagrant box add mynewbox mynew.box vagrant destroy vagrant init mynewbox after that I can run my own box: vagrant up I can also upload that box up to atlas storage ruthkraus/ubuntu14_psql93 For that there I need to configure provider, version, upload image and then release it.","tags":"Blog","url":"https://ruthkraus.github.io/2017/06/prepare-own-vagrant-box-from-existing.html","loc":"https://ruthkraus.github.io/2017/06/prepare-own-vagrant-box-from-existing.html"},{"title":"Use Packer to prepare custom Vagrant box","text":"What is Packer? Packer is an open source tool for creating identical machine images for multiple platforms from a single source configuration. Packer is lightweight, runs on every major operating system, and is highly performant, creating machine images for multiple platforms in parallel. Packer does not replace configuration management like Chef or Puppet. In fact, when building images, Packer is able to use tools like Chef or Puppet to install software onto the image. A machine image is a single static unit that contains a pre-configured operating system and installed software which is used to quickly create new running machines. Machine image formats change for each platform. Some examples include AMIs for EC2 , VMDK / VMX files for VMware, OVF exports for VirtualBox, etc. Packer documentation Here I want to write down how to use template file to prepare my own box from one of base boxes from https://atlas.hashicorp.com site. It's maybe not usual approach, I want just to play with Packer, their arguments, etc. I think probably in real life it's enough to use Vagrantfile with one of provision methods. But here I want to learn how to create my own box from existing base box with Packer. I decided to use hashicorp/precise64 box, so first I init box vagrant init hashicorp/precise64 Then I know that box can be found by path $ HOME /.vagrant/boxes/hashicorp- VAGRANTSLASH -precise64/1.1.0/virtualbox/box.ovf So I want to create my own box with 1Gb RAM , 2 CPU based on initial hashicorp/precise64 box. I want to provision machine with bash script that installs some additional packages, then I want to get my own box as artifact and upload it to my atlas storage. Script bootstrap.sh that I want to ask to Packer to run during provisioning\\ looks like: #!/usr/bin/env bash sudo apt-get update sudo apt-get install -y apache2 if ! [ -L /var/www ] ; then sudo rm -rf /var/www sudo ln -fs /vagrant /var/www fi sudo apt-get install -y mc sudo apt-get install -y htop sudo apt-get install -y postgresql-9.1 postgresql-server-dev-9.1 libpq-dev python-dev python-setuptools sudo apt-get clean Template file called as packer.json : { \"variables\" : { \"home\" : \"{{env `USERPROFILE`}}\" }, \"builders\" : [{ \"type\" : \"virtualbox-ovf\" , \"source_path\" : \"{{ user `home` }}/.vagrant.d/boxes/hashicorp-VAGRANTSLASH-precise64/1.1.0/virtualbox/box.ovf\" , \"ssh_username\" : \"vagrant\" , \"ssh_password\" : \"vagrant\" , \"ssh_wait_timeout\" : \"30s\" , \"guest_additions_mode\" : \"disable\" , \"shutdown_command\" : \"echo 'packer' | sudo -S shutdown -P now\" , \"vboxmanage\" : [ [ \"modifyvm\" , \"{{.Name}}\" , \"--memory\" , \"1024\" ], [ \"modifyvm\" , \"{{.Name}}\" , \"--cpus\" , \"2\" ]] }], \"provisioners\" : [{ \"type\" : \"shell\" , \"script\" : \"bootstrap.sh\" , \"pause_before\" : \"30s\" }], \"post-processors\" : [{ \"type\" : \"vagrant\" , \"keep_input_artifact\" : true , \"output\" : \"box/modified-hashicorp-VAGRANTSLASH-precise64.box\" }, { \"type\" : \"atlas\" , \"artifact\" : \"ruthkraus/precise64\" , \"artifact_type\" : \"vagrant.box\" , \"metadata\" : { \"provider\" : \"virtualbox\" , \"version\" : \"1.0.0\" } } ] } The one thing, to upload artifact to atlas via ‘atlas' post-processor, I have to create ATLAS_TOKEN and set it to my environment variables. To start Packer to build packer build packer.json After that Virtualbox manager will be shown and process logged into console: When build succeed, I can see my uploaded box in my vagrant boxes list. The one thing, if I upload box via atlas post-processor, this box is uploaded to the not free area and I need to pay money to use it, there Atlas gave me trial 1 month period. I removed box that I played with, but I still can use box that Packer created \"box/modified-hashicorp- VAGRANTSLASH -precise64.box\" vagrant box add mybox modified-hashicorp-VAGRANTSLASH-precise64.box cd ../mybox vagrant init mybox vagrant up So probably the way, when I create box manually on Vagrant site is more preferable for me now, it is free, but yes it requires some additional manual work. It's not so cool like auto create by atlas post-processor. Keep VirtualBOX additions fresh I found that almost all Ubuntu images that I used to play with, have old VirtualBox addition pack. It's very useful plugin to keep always Vbox additions fresh version. The next command installs vagrant-vbguest on machine and every vagrant up command at the end it checks if Vbox additions are freshest and updates it if that is necessary. vagrant plugin install vagrant-vbguest","tags":"Blog","url":"https://ruthkraus.github.io/2017/06/use-packer-for-prepare-custom-box.html","loc":"https://ruthkraus.github.io/2017/06/use-packer-for-prepare-custom-box.html"},{"title":"Pelican plugin for Jupyter/IPython Notebooks","text":"Today I read about nice thing that called as Jupyter I installed its locally, it's cool to play with python there and store results in files with .ipynb extension locally. Then I found that it is plugin pelican-ipynb for Pelican. With that plugin enabled, Pelican easy creates html pages with proper markup like into Jupyter. I'll try to use it sometimes, to avoid copying code samples from ipython console to markdown files. Its possible to convert .ipynb content to nice formatted article ! So I created separate plugins folder in my site hierarchy and cloned repo pelican-ipynb into my plugins folder to ipynb directory. $ git clone https://github.com/danielfrg/pelican-ipynb ipynb So my tree looks like plugins/ └── ipynb ├── core.py ├── __init__.py ├── ipynb.py ├── liquid.py ├── markup.py ... In pelicanconf.py file I added \"ipynb.markup\" to PLUGINS list. PLUGINS = [ 'i18n_subsites' , 'related_posts' , \"tag_cloud\" , \"tipue_search\" , \"ipynb.markup\" ] Then add MARKUP = ( 'md' , 'ipynb' ) And added new plugins path PLUGIN_PATHS = ['pelican-plugins/', 'plugins/'] That's all settings. In next article I'll try to use this plugin. P.S. I had to fork ipynb repo and did little fix, to make date in metadata file .ipynb-meta not mandatory. So now I use fork pelican-ipynb","tags":"Blog","url":"https://ruthkraus.github.io/2017/06/add-ipynb-plugin-to-pelican.html","loc":"https://ruthkraus.github.io/2017/06/add-ipynb-plugin-to-pelican.html"},{"title":"How to add DISQUS comments to Pelican site","text":"It is possible to attach DISQUS comments to blog site. Setup your DISQUS Account Before you can use the commenting stuff, you need to register into Disqus. There you find a lot of disqus documentation that you simply not need :-) . Pelican already has done that for you. Register on DISQUS site Select ‘I don't see my platform listed, install manually with Universal Code. Remember ‘Shortname'=ruthkraus, it will be used later in site configuration. Fill fields Website name and Website URL . Check ‘Allow guests to comments' Finish settings with Add trusted site, my own is ruthkraus.github.io Into pelicanconf.py file enable DISQUS , just add these settings: DISQUS_SITENAME = \"ruthkraus\" Remember, here should be added ‘shortname' from step 3. That's done, now generate content and check that comments working fine:","tags":"Blog","url":"https://ruthkraus.github.io/2017/06/how-to-add-disqus-comments.html","loc":"https://ruthkraus.github.io/2017/06/how-to-add-disqus-comments.html"},{"title":"Start blog site on GitHub pages with Pelican","text":"One day I found that I forgot many things I learned and used before, so I decided to make short memos about different programming aspects, issues and new tools I'll learn and touch in the future. Create GitHub user page GitHub provides easy and nice possibility to create your own site with User Pages So as described in this tutoral I've created repo with special name ruthkraus.github.io The content from master branch from this repo should be used to display on access https://ruthkraus.github.io url. Create site with Pelican I found that possibility that provided from GitHub to have static pages with jekyll is nice, but Pelican is more powerful tool, with rich number of plugins and nice themes. So I checkout my ruthkraus.github.io repository from branch master to pelican branch and start to install Pelican. Step 1. Install Pelican. $ virtualenv -p python3.6 .env $ source .env/bin/activate ( .env ) $ pip install pelican markdown Step 2. Get pelican-plugins and pelican-themes submodules After review many nice themes on site http://www.pelicanthemes.com/ I've decided to use pelican-bootstrap3 theme, with little changes, so I've forked pelican-themes repo to make custom changes. $ git submodule add git@github.com:getpelican/pelican-plugins.git pelican-plugins $ git submodule add https://github.com/ruthkraus/pelican-themes pelican-themes Step 3. Create simple site template Once Pelican has been installed, you can create a skeleton project via the pelican-quickstart command, which begins by asking some questions about your site. pelican-quickstart Then answer to questions or keep just all defaults, it's possible to change all later, manually in file pelicanconf.py Step 4. Configure pelicanconf.py The all possible settings are described in documentation My settings file looks like: #!/usr/bin/env python # -*- coding: utf-8 -*- # from __future__ import unicode_literals AUTHOR = 'Ruth Kraus' SITENAME = 'ruthkraus.github.io' SITEURL = 'https://ruthkraus.github.io' PATH = 'content' TIMEZONE = 'Europe/Moscow' DEFAULT_LANG = 'en' # Feed generation is usually not desired when developing FEED_ALL_ATOM = None CATEGORY_FEED_ATOM = None TRANSLATION_FEED_ATOM = None AUTHOR_FEED_ATOM = None AUTHOR_FEED_RSS = None SHOW_ARTICLE_AUTHOR = True SHOW_DATE_MODIFIED = True # Show my last activity on GitHub GITHUB_USER = 'ruthkraus' # Enable custom theme THEME = \"pelican-themes/pelican-bootstrap3/\" BOOTSTRAP_THEME = \"flatly\" JINJA_ENVIRONMENT = { 'extensions' : [ 'jinja2.ext.i18n' ]} PYGMENTS_STYLE = 'emacs' DEFAULT_DATE = 'fs' # Enable plugins PLUGIN_PATHS = [ 'pelican-plugins/' ] PLUGINS = [ 'i18n_subsites' ] # Enable disqus comments DISQUS_SITENAME = \"ruthkraus\" SITELOGO = 'images/logo.png' STATIC_PATHS = [ 'images' , 'extra/custom.css' ] CUSTOM_CSS = 'theme/css/custom.css' EXTRA_PATH_METADATA = { 'extra/custom.css' : { 'path' : 'theme/css/custom.css' } } # Blogroll LINKS = (( 'Pelican' , 'http://getpelican.com/' ), ( 'Python.org' , 'http://python.org/' ), ( 'Jinja2' , 'http://jinja.pocoo.org/' ), ( 'Django' , 'https://https://docs.djangoproject.com/' ), ( 'Flask' , 'http://flask.pocoo.org/' ), ) # Social widget SOCIAL = (( 'vk' , 'https://vk.com/id216671695' ), ( 'Facebook' , 'https://www.facebook.com/alexander.ruthkraus' ), ( 'GitHub' , 'https://github.com/ruthkraus' ),) DEFAULT_PAGINATION = 5 # Uncomment following line if you want document-relative URLs when developing RELATIVE_URLS = False DELETE_OUTPUT_DIRECTORY = True TYPOGRIFY = True Step 5. Add some content I've added this page in .md format into content/20170613-start-site-with-pelican.md file Step 6. Use Fabric to manage site It's possible to use fabric utility to make some useful things with site content, like run dev server and push changes to GitHub pages I've used Fabric3 to use with python3.6 on my machine Install Fabric3 pip install fabric3 ghp - import Fix fabfile.py (for usage with python3) Change import SocketServer to import socketserver To use fab command to start dev server , run $ fab serve To publish content to master branch on github repo, run $ fab gh_pages P.S. After couple days I've changed this command to fab push Part 2 - How to enable DISQUS comments","tags":"Blog","url":"https://ruthkraus.github.io/2017/06/start-site-with-pelican.html","loc":"https://ruthkraus.github.io/2017/06/start-site-with-pelican.html"}]};